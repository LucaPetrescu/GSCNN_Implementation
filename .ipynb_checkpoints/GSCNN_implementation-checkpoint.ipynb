{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecec23b0",
   "metadata": {},
   "source": [
    "## Implementation of GSCNN in a Jupyter Notebook\n",
    "\n",
    "In this Jupyter Notebook, we will implement GSCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5caf7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from network import Resnet\n",
    "from network.mynn import initialize_weights, Norm2d\n",
    "from network.wider_resnet import WiderResNetA2\n",
    "\n",
    "from my_functionals import GatedSpatialConv as gsc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0121768",
   "metadata": {},
   "source": [
    "The device we would like to train our network on would ideally to be out graphics card. However, in case we do not \n",
    "have a graphics card, then the device will be the CPU by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08a6caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36d245",
   "metadata": {},
   "source": [
    "#### Part 1 - Implementing the Network Architecture\n",
    "\n",
    "Here we define the basic architecture of the network. In includes several classes, but we will explain each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48d4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop(nn.Module):\n",
    "    def __init__(self, axis, offset):\n",
    "        super(Crop, self).__init__()\n",
    "        self.axis = axis\n",
    "        self.offset = offset\n",
    "\n",
    "    def forward(self, x, ref):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: input layer\n",
    "        :param ref: reference usually data in\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for axis in range(self.axis, x.dim()):\n",
    "            ref_size = ref.size(axis)\n",
    "            indices = torch.arange(self.offset, self.offset + ref_size).long()\n",
    "            indices = x.data.new().resize_(indices.size()).copy_(indices).long()\n",
    "            x = x.index_select(axis, Variable(indices))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72a79e",
   "metadata": {},
   "source": [
    "The **Crop** class is used to extract a subregion from an input tensor based on a reference tensor. \n",
    "It is a useful tool for data augmentation and other tasks that require extracting specific elements from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b670cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIdentity(nn.Module):\n",
    "    def __init__(self, axis, offset):\n",
    "        super(MyIdentity, self).__init__()\n",
    "        self.axis = axis\n",
    "        self.offset = offset\n",
    "\n",
    "    def forward(self, x, ref):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: input layer\n",
    "        :param ref: reference usually data in\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256e6c4",
   "metadata": {},
   "source": [
    "The **MyIdentity** class in the provided code snippet is a custom neural network layer that simply returns the input tensor x without any modification. It takes two arguments in its constructor: **axis** and **offset**. These arguments are not used in the forward method and are likely just there to maintain consistency with the **Crop** class.\n",
    "\n",
    "The **forward** method of the **MyIdentity** class simply returns the input tensor **x** without any further processing. This indicates that the layer does not perform any transformation on the input data. It is essentially a pass-through layer that allows data to flow through the network without any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f94888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SideOutputCrop(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the original implementation ConvTranspose2d (fixed) and crops\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_output, kernel_sz=None, stride=None, upconv_pad=0, do_crops=True):\n",
    "        super(SideOutputCrop, self).__init__()\n",
    "        self._do_crops = do_crops\n",
    "        self.conv = nn.Conv2d(num_output, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        if kernel_sz is not None:\n",
    "            self.upsample = True\n",
    "            self.upsampled = nn.ConvTranspose2d(1, out_channels=1, kernel_size=kernel_sz, stride=stride,\n",
    "                                                padding=upconv_pad,\n",
    "                                                bias=False)\n",
    "            ##doing crops\n",
    "            if self._do_crops:\n",
    "                self.crops = Crop(2, offset=kernel_sz // 4)\n",
    "            else:\n",
    "                self.crops = MyIdentity(None, None)\n",
    "        else:\n",
    "            self.upsample = False\n",
    "\n",
    "    def forward(self, res, reference=None):\n",
    "        side_output = self.conv(res)\n",
    "        if self.upsample:\n",
    "            side_output = self.upsampled(side_output)\n",
    "            side_output = self.crops(side_output, reference)\n",
    "\n",
    "        return side_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b123072",
   "metadata": {},
   "source": [
    "The **SideOutputCrop** class is used to generate side output for a CNN. It can optionally apply upsampling and cropping to the side output. Upsampling is useful for increasing the spatial resolution of the side output, while cropping can be used to remove irrelevant or redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b4e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AtrousSpatialPyramidPoolingModule(nn.Module):\n",
    "    '''\n",
    "    operations performed:\n",
    "      1x1 x depth\n",
    "      3x3 x depth dilation 6\n",
    "      3x3 x depth dilation 12\n",
    "      3x3 x depth dilation 18\n",
    "      image pooling\n",
    "      concatenate all together\n",
    "      Final 1x1 conv\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_dim, reduction_dim=256, output_stride=16, rates=[6, 12, 18]):\n",
    "        super(_AtrousSpatialPyramidPoolingModule, self).__init__()\n",
    "\n",
    "        # Check if we are using distributed BN and use the nn from encoding.nn\n",
    "        # library rather than using standard pytorch.nn\n",
    "\n",
    "        if output_stride == 8:\n",
    "            rates = [2 * r for r in rates]\n",
    "        elif output_stride == 16:\n",
    "            pass\n",
    "        else:\n",
    "            raise 'output stride of {} not supported'.format(output_stride)\n",
    "\n",
    "        self.features = []\n",
    "        # 1x1\n",
    "        self.features.append(\n",
    "            nn.Sequential(nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "                          Norm2d(reduction_dim), nn.ReLU(inplace=True)))\n",
    "        # other rates\n",
    "        for r in rates:\n",
    "            self.features.append(nn.Sequential(\n",
    "                nn.Conv2d(in_dim, reduction_dim, kernel_size=3,\n",
    "                          dilation=r, padding=r, bias=False),\n",
    "                Norm2d(reduction_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.features = torch.nn.ModuleList(self.features)\n",
    "\n",
    "        # img level features\n",
    "        self.img_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.img_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "            Norm2d(reduction_dim), nn.ReLU(inplace=True))\n",
    "        self.edge_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, reduction_dim, kernel_size=1, bias=False),\n",
    "            Norm2d(reduction_dim), nn.ReLU(inplace=True))\n",
    "         \n",
    "\n",
    "    def forward(self, x, edge):\n",
    "        x_size = x.size()\n",
    "\n",
    "        img_features = self.img_pooling(x)\n",
    "        img_features = self.img_conv(img_features)\n",
    "        img_features = F.interpolate(img_features, x_size[2:],\n",
    "                                     mode='bilinear',align_corners=True)\n",
    "        out = img_features\n",
    "\n",
    "        edge_features = F.interpolate(edge, x_size[2:],\n",
    "                                      mode='bilinear',align_corners=True)\n",
    "        edge_features = self.edge_conv(edge_features)\n",
    "        out = torch.cat((out, edge_features), 1)\n",
    "\n",
    "        for f in self.features:\n",
    "            y = f(x)\n",
    "            out = torch.cat((out, y), 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935eb20d",
   "metadata": {},
   "source": [
    "The **_AtrousSpatialPyramidPoolingModule** class in the provided code snippet is a neural network module that performs atrous spatial pyramid pooling (ASPP) on the input feature map. ASPP is a technique for aggregating information from multiple feature scales in a single module. This can be useful for improving the performance of semantic segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e050349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSCNN(nn.Module):\n",
    "    '''\n",
    "    Wide_resnet version of DeepLabV3\n",
    "    mod1\n",
    "    pool2\n",
    "    mod2 str2\n",
    "    pool3\n",
    "    mod3-7\n",
    "\n",
    "      structure: [3, 3, 6, 3, 1, 1]\n",
    "      channels = [(128, 128), (256, 256), (512, 512), (512, 1024), (512, 1024, 2048),\n",
    "                  (1024, 2048, 4096)]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_classes, trunk=None, criterion=None):\n",
    "        \n",
    "        super(GSCNN, self).__init__()\n",
    "        self.criterion = criterion\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        structure = [3, 3, 6, 3, 1, 1]\n",
    "        \n",
    "        wide_resnet = WiderResNetA2(structure, classes=1000, dilation=True)\n",
    "        wide_resnet = torch.nn.DataParallel(wide_resnet)\n",
    "        \n",
    "        wide_resnet = wide_resnet.module\n",
    "        self.mod1 = wide_resnet.mod1\n",
    "        self.mod2 = wide_resnet.mod2\n",
    "        self.mod3 = wide_resnet.mod3\n",
    "        self.mod4 = wide_resnet.mod4\n",
    "        self.mod5 = wide_resnet.mod5\n",
    "        self.mod6 = wide_resnet.mod6\n",
    "        self.mod7 = wide_resnet.mod7\n",
    "        self.pool2 = wide_resnet.pool2\n",
    "        self.pool3 = wide_resnet.pool3\n",
    "        self.interpolate = F.interpolate\n",
    "        del wide_resnet\n",
    "        \n",
    "        self.dsn1 = nn.Conv2d(64, 1, 1)\n",
    "        self.dsn3 = nn.Conv2d(256, 1, 1)\n",
    "        self.dsn4 = nn.Conv2d(512, 1, 1)\n",
    "        self.dsn7 = nn.Conv2d(4096, 1, 1)\n",
    "\n",
    "        self.res1 = Resnet.BasicBlock(64, 64, stride=1, downsample=None)\n",
    "        self.d1 = nn.Conv2d(64, 32, 1)\n",
    "        self.res2 = Resnet.BasicBlock(32, 32, stride=1, downsample=None)\n",
    "        self.d2 = nn.Conv2d(32, 16, 1)\n",
    "        self.res3 = Resnet.BasicBlock(16, 16, stride=1, downsample=None)\n",
    "        self.d3 = nn.Conv2d(16, 8, 1)\n",
    "        self.fuse = nn.Conv2d(8, 1, kernel_size=1, padding=0, bias=False)\n",
    "        \n",
    "        self.cw = nn.Conv2d(2, 1, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.gate1 = gsc.GatedSpatialConv2d(32, 32)\n",
    "        self.gate2 = gsc.GatedSpatialConv2d(16, 16)\n",
    "        self.gate3 = gsc.GatedSpatialConv2d(8, 8)\n",
    "         \n",
    "        self.aspp = _AtrousSpatialPyramidPoolingModule(4096, 256,\n",
    "                                                       output_stride=8)\n",
    "\n",
    "        self.bot_fine = nn.Conv2d(128, 48, kernel_size=1, bias=False)\n",
    "        self.bot_aspp = nn.Conv2d(1280 + 256, 256, kernel_size=1, bias=False)\n",
    "        \n",
    "        self.final_seg = nn.Sequential(\n",
    "            nn.Conv2d(256 + 48, 256, kernel_size=3, padding=1, bias=False),\n",
    "            Norm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            Norm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1, bias=False))\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        initialize_weights(self.final_seg)\n",
    "        \n",
    "    def forward(self, inp, gts=None):\n",
    "\n",
    "        x_size = inp.size() \n",
    "\n",
    "        # res 1\n",
    "        m1 = self.mod1(inp)\n",
    "\n",
    "        # res 2\n",
    "        m2 = self.mod2(self.pool2(m1))\n",
    "\n",
    "        # res 3\n",
    "        m3 = self.mod3(self.pool3(m2))\n",
    "\n",
    "        # res 4-7\n",
    "        m4 = self.mod4(m3)\n",
    "        m5 = self.mod5(m4)\n",
    "        m6 = self.mod6(m5)\n",
    "        m7 = self.mod7(m6) \n",
    "\n",
    "        s3 = F.interpolate(self.dsn3(m3), x_size[2:],\n",
    "                            mode='bilinear', align_corners=True)\n",
    "        s4 = F.interpolate(self.dsn4(m4), x_size[2:],\n",
    "                            mode='bilinear', align_corners=True)\n",
    "        s7 = F.interpolate(self.dsn7(m7), x_size[2:],\n",
    "                            mode='bilinear', align_corners=True)\n",
    "        \n",
    "        m1f = F.interpolate(m1, x_size[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        im_arr = inp.cpu().numpy().transpose((0,2,3,1)).astype(np.uint8)\n",
    "        canny = np.zeros((x_size[0], 1, x_size[2], x_size[3]))\n",
    "        for i in range(x_size[0]):\n",
    "            canny[i] = cv2.Canny(im_arr[i],10,100)\n",
    "        canny = torch.from_numpy(canny).cuda().float()\n",
    "\n",
    "        cs = self.res1(m1f)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        cs = self.d1(cs)\n",
    "        cs = self.gate1(cs, s3)\n",
    "        cs = self.res2(cs)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        cs = self.d2(cs)\n",
    "        cs = self.gate2(cs, s4)\n",
    "        cs = self.res3(cs)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        cs = self.d3(cs)\n",
    "        cs = self.gate3(cs, s7)\n",
    "        cs = self.fuse(cs)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        edge_out = self.sigmoid(cs)\n",
    "        cat = torch.cat((edge_out, canny), dim=1)\n",
    "        acts = self.cw(cat)\n",
    "        acts = self.sigmoid(acts)\n",
    "\n",
    "        # aspp\n",
    "        x = self.aspp(m7, acts)\n",
    "        dec0_up = self.bot_aspp(x)\n",
    "\n",
    "        dec0_fine = self.bot_fine(m2)\n",
    "        dec0_up = self.interpolate(dec0_up, m2.size()[2:], mode='bilinear',align_corners=True)\n",
    "        dec0 = [dec0_fine, dec0_up]\n",
    "        dec0 = torch.cat(dec0, 1)\n",
    "\n",
    "        dec1 = self.final_seg(dec0)  \n",
    "        seg_out = self.interpolate(dec1, x_size[2:], mode='bilinear')            \n",
    "       \n",
    "        if self.training:\n",
    "            return self.criterion((seg_out, edge_out), gts)              \n",
    "        else:\n",
    "            return seg_out, edge_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca76869",
   "metadata": {},
   "source": [
    "### Part 2 - Training and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d683ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import argparse\n",
    "from functools import partial\n",
    "from config import cfg, assert_and_infer_cfg\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils.misc import AverageMeter, prep_experiment, evaluate_eval, fast_hist\n",
    "from utils.f_boundary import eval_mask_boundary\n",
    "import datasets\n",
    "import loss\n",
    "import network\n",
    "import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6886026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument Parser\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import argparse\n",
    "from functools import partial\n",
    "from config import cfg, assert_and_infer_cfg\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils.misc import AverageMeter, prep_experiment, evaluate_eval, fast_hist\n",
    "from utils.f_boundary import eval_mask_boundary\n",
    "import datasets\n",
    "import loss\n",
    "import network\n",
    "import optimizer\n",
    "\n",
    "# Argument Parser\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GSCNN')\n",
    "\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--arch', type=str, default='network.gscnn.GSCNN')\n",
    "parser.add_argument('--dataset', type=str, default='cityscapes')\n",
    "parser.add_argument('--cv', type=int, default=0,\n",
    "                    help='cross validation split')\n",
    "parser.add_argument('--joint_edgeseg_loss', action='store_true', default=True,\n",
    "                    help='joint loss')\n",
    "parser.add_argument('--img_wt_loss', action='store_true', default=False,\n",
    "                    help='per-image class-weighted loss')\n",
    "parser.add_argument('--batch_weighting', action='store_true', default=False,\n",
    "                    help='Batch weighting for class')\n",
    "parser.add_argument('--eval_thresholds', type=str, default='0.0005,0.001875,0.00375,0.005',\n",
    "                    help='Thresholds for boundary evaluation')\n",
    "parser.add_argument('--rescale', type=float, default=1.0,\n",
    "                    help='Rescaled LR Rate')\n",
    "parser.add_argument('--repoly', type=float, default=1.5,\n",
    "                    help='Rescaled Poly')\n",
    "\n",
    "parser.add_argument('--edge_weight', type=float, default=1.0,\n",
    "                    help='Edge loss weight for joint loss')\n",
    "parser.add_argument('--seg_weight', type=float, default=1.0,\n",
    "                    help='Segmentation loss weight for joint loss')\n",
    "parser.add_argument('--att_weight', type=float, default=1.0,\n",
    "                    help='Attention loss weight for joint loss')\n",
    "parser.add_argument('--dual_weight', type=float, default=1.0,\n",
    "                    help='Dual loss weight for joint loss')\n",
    "\n",
    "parser.add_argument('--evaluate', action='store_true', default=False)\n",
    "\n",
    "parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "parser.add_argument('--sgd', action='store_true', default=True)\n",
    "parser.add_argument('--sgd_finetuned',action='store_true',default=False)\n",
    "parser.add_argument('--adam', action='store_true', default=False)\n",
    "parser.add_argument('--amsgrad', action='store_true', default=False)\n",
    "\n",
    "parser.add_argument('--trunk', type=str, default='resnet101',\n",
    "                    help='trunk model, can be: resnet101 (default), resnet50')\n",
    "parser.add_argument('--max_epoch', type=int, default=175)\n",
    "parser.add_argument('--start_epoch', type=int, default=0)\n",
    "parser.add_argument('--color_aug', type=float,\n",
    "                    default=0.25, help='level of color augmentation')\n",
    "parser.add_argument('--rotate', type=float,\n",
    "                    default=0, help='rotation')\n",
    "parser.add_argument('--gblur', action='store_true', default=True)\n",
    "parser.add_argument('--bblur', action='store_true', default=False) \n",
    "parser.add_argument('--lr_schedule', type=str, default='poly',\n",
    "                    help='name of lr schedule: poly')\n",
    "parser.add_argument('--poly_exp', type=float, default=1.0,\n",
    "                    help='polynomial LR exponent')\n",
    "parser.add_argument('--bs_mult', type=int, default=10)\n",
    "parser.add_argument('--bs_mult_val', type=int, default=2)\n",
    "parser.add_argument('--crop_size', type=int, default=720,\n",
    "                    help='training crop size')\n",
    "parser.add_argument('--pre_size', type=int, default=None,\n",
    "                    help='resize image shorter edge to this before augmentation')\n",
    "parser.add_argument('--scale_min', type=float, default=0.5,\n",
    "                    help='dynamically scale training images down to this size')\n",
    "parser.add_argument('--scale_max', type=float, default=2.0,\n",
    "                    help='dynamically scale training images up to this size')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "parser.add_argument('--momentum', type=float, default=0.9)\n",
    "parser.add_argument('--snapshot', type=str, default=None)\n",
    "parser.add_argument('--restore_optimizer', action='store_true', default=False)\n",
    "parser.add_argument('--exp', type=str, default='default',\n",
    "                    help='experiment directory name')\n",
    "parser.add_argument('--tb_tag', type=str, default='',\n",
    "                    help='add tag to tb dir')\n",
    "parser.add_argument('--ckpt', type=str, default='logs/ckpt')\n",
    "parser.add_argument('--tb_path', type=str, default='logs/tb')\n",
    "parser.add_argument('--syncbn', action='store_true', default=True,\n",
    "                    help='Synchronized BN')\n",
    "parser.add_argument('--dump_augmentation_images', action='store_true', default=False,\n",
    "                    help='Synchronized BN')\n",
    "parser.add_argument('--test_mode', action='store_true', default=False,\n",
    "                    help='minimum testing (1 epoch run ) to verify nothing failed')\n",
    "parser.add_argument('-wb', '--wt_bound', type=float, default=1.0)\n",
    "parser.add_argument('--maxSkip', type=int, default=0)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "def start():\n",
    "    assert_and_infer_cfg(args)\n",
    "    writer = prep_experiment(args,parser)\n",
    "    train_loader, val_loader, train_obj = datasets.setup_loaders(args)\n",
    "    criterion, criterion_val = loss.get_loss(args)\n",
    "    net = network.get_net(args, criterion)\n",
    "    optim, scheduler = optimizer.get_optimizer(args, net)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if args.evaluate:\n",
    "        # Early evaluation for benchmarking\n",
    "        default_eval_epoch = 1\n",
    "        validate(val_loader, net, criterion_val,\n",
    "                    optim, default_eval_epoch, writer)\n",
    "        evaluate(val_loader, net)\n",
    "        return\n",
    "\n",
    "\n",
    "    #Main Loop\n",
    "    for epoch in range(args.start_epoch, args.max_epoch):\n",
    "    # Update EPOCH CTR\n",
    "        cfg.immutable(False)\n",
    "        cfg.EPOCH  = epoch\n",
    "        cfg.immutable(True)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        train(train_loader, net, criterion, optim, epoch, writer)\n",
    "        validate(val_loader, net, criterion_val,\n",
    "                optim, epoch, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0796b8c",
   "metadata": {},
   "source": [
    "#### Part 2.1 - Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70003415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train method\n",
    "\n",
    "def train(train_loader, net, criterion, optimizer, curr_epoch, writer):\n",
    "    '''\n",
    "    Runs the training loop per epoch\n",
    "    train_loader: Data loader for train\n",
    "    net: thet network\n",
    "    criterion: loss fn\n",
    "    optimizer: optimizer\n",
    "    curr_epoch: current epoch \n",
    "    writer: tensorboard writer\n",
    "    return: val_avg for step function if required\n",
    "    '''\n",
    "    net.train()\n",
    "\n",
    "    train_main_loss = AverageMeter()\n",
    "    train_edge_loss = AverageMeter()\n",
    "    train_seg_loss = AverageMeter()\n",
    "    train_att_loss = AverageMeter()\n",
    "    train_dual_loss = AverageMeter()\n",
    "    curr_iter = curr_epoch * len(train_loader)\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if i==0:\n",
    "            print('running....')\n",
    "\n",
    "        inputs, mask, edge, _img_name = data\n",
    "\n",
    "        if torch.sum(torch.isnan(inputs)) > 0:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        batch_pixel_size = inputs.size(0) * inputs.size(2) * inputs.size(3)\n",
    "\n",
    "        inputs, mask, edge = inputs.cuda(), mask.cuda(), edge.cuda()\n",
    "\n",
    "        if i==0:\n",
    "            print('forward done')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        main_loss = None\n",
    "        loss_dict = None\n",
    "\n",
    "        if args.joint_edgeseg_loss:\n",
    "            loss_dict = net(inputs, gts=(mask, edge))\n",
    "            \n",
    "            if args.seg_weight > 0:\n",
    "                log_seg_loss = loss_dict['seg_loss'].mean().clone().detach_()\n",
    "                train_seg_loss.update(log_seg_loss.item(), batch_pixel_size)\n",
    "                main_loss = loss_dict['seg_loss']\n",
    "\n",
    "            if args.edge_weight > 0:\n",
    "                log_edge_loss = loss_dict['edge_loss'].mean().clone().detach_()\n",
    "                train_edge_loss.update(log_edge_loss.item(), batch_pixel_size)\n",
    "                if main_loss is not None:\n",
    "                    main_loss += loss_dict['edge_loss']\n",
    "                else:\n",
    "                    main_loss = loss_dict['edge_loss']\n",
    "            \n",
    "            if args.att_weight > 0:\n",
    "                log_att_loss = loss_dict['att_loss'].mean().clone().detach_()\n",
    "                train_att_loss.update(log_att_loss.item(), batch_pixel_size)\n",
    "                if main_loss is not None:\n",
    "                    main_loss += loss_dict['att_loss']\n",
    "                else:\n",
    "                    main_loss = loss_dict['att_loss']\n",
    "\n",
    "            if args.dual_weight > 0:\n",
    "                log_dual_loss = loss_dict['dual_loss'].mean().clone().detach_()\n",
    "                train_dual_loss.update(log_dual_loss.item(), batch_pixel_size)\n",
    "                if main_loss is not None:\n",
    "                    main_loss += loss_dict['dual_loss']\n",
    "                else:\n",
    "                    main_loss = loss_dict['dual_loss']\n",
    "\n",
    "        else:\n",
    "            main_loss = net(inputs, gts=mask)\n",
    "\n",
    "        main_loss = main_loss.mean()\n",
    "        log_main_loss = main_loss.clone().detach_()\n",
    "\n",
    "        train_main_loss.update(log_main_loss.item(), batch_pixel_size)\n",
    "\n",
    "        main_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i==0:\n",
    "            print('step 1 done')\n",
    "\n",
    "        curr_iter += 1\n",
    "\n",
    "        if args.local_rank == 0:\n",
    "            msg = '[epoch {}], [iter {} / {}], [train main loss {:0.6f}], [seg loss {:0.6f}], [edge loss {:0.6f}], [lr {:0.6f}]'.format(\n",
    "            curr_epoch, i + 1, len(train_loader), train_main_loss.avg, train_seg_loss.avg, train_edge_loss.avg, optimizer.param_groups[-1]['lr'] )\n",
    "\n",
    "            logging.info(msg)\n",
    "\n",
    "            # Log tensorboard metrics for each iteration of the training phase\n",
    "            writer.add_scalar('training/loss', (train_main_loss.val),\n",
    "                              curr_iter)\n",
    "            writer.add_scalar('training/lr', optimizer.param_groups[-1]['lr'],\n",
    "                              curr_iter)\n",
    "            if args.joint_edgeseg_loss:\n",
    "\n",
    "                writer.add_scalar('training/seg_loss', (train_seg_loss.val),\n",
    "                                  curr_iter)\n",
    "                writer.add_scalar('training/edge_loss', (train_edge_loss.val),\n",
    "                                  curr_iter)\n",
    "                writer.add_scalar('training/att_loss', (train_att_loss.val),\n",
    "                                  curr_iter)\n",
    "                writer.add_scalar('training/dual_loss', (train_dual_loss.val),\n",
    "                                  curr_iter)\n",
    "        if i > 5 and args.test_mode:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235f922",
   "metadata": {},
   "source": [
    "#### Part 2.2 - Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd75ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, net, criterion, optimizer, curr_epoch, writer):\n",
    "    '''\n",
    "    Runs the validation loop after each training epoch\n",
    "    val_loader: Data loader for validation\n",
    "    net: thet network\n",
    "    criterion: loss fn\n",
    "    optimizer: optimizer\n",
    "    curr_epoch: current epoch \n",
    "    writer: tensorboard writer\n",
    "    return: \n",
    "    '''\n",
    "    net.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    mf_score = AverageMeter()\n",
    "    IOU_acc = 0\n",
    "    dump_images = []\n",
    "    heatmap_images = []\n",
    "    for vi, data in enumerate(val_loader):\n",
    "        input, mask, edge, img_names = data\n",
    "        assert len(input.size()) == 4 and len(mask.size()) == 3\n",
    "        assert input.size()[2:] == mask.size()[1:]\n",
    "        h, w = mask.size()[1:]\n",
    "\n",
    "        batch_pixel_size = input.size(0) * input.size(2) * input.size(3)\n",
    "        input, mask_cuda, edge_cuda = input.cuda(), mask.cuda(), edge.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            seg_out, edge_out = net(input)    # output = (1, 19, 713, 713)\n",
    "\n",
    "        if args.joint_edgeseg_loss:\n",
    "            loss_dict = criterion((seg_out, edge_out), (mask_cuda, edge_cuda))\n",
    "            val_loss.update(sum(loss_dict.values()).item(), batch_pixel_size)\n",
    "        else:\n",
    "            val_loss.update(criterion(seg_out, mask_cuda).item(), batch_pixel_size)\n",
    "\n",
    "        # Collect data from different GPU to a single GPU since\n",
    "        # encoding.parallel.criterionparallel function calculates distributed loss\n",
    "        # functions\n",
    "\n",
    "        seg_predictions = seg_out.data.max(1)[1].cpu()\n",
    "        edge_predictions = edge_out.max(1)[0].cpu()\n",
    "\n",
    "        #Logging\n",
    "        if vi % 20 == 0:\n",
    "            if args.local_rank == 0:\n",
    "                logging.info('validating: %d / %d' % (vi + 1, len(val_loader)))\n",
    "        if vi > 10 and args.test_mode:\n",
    "            break\n",
    "        _edge = edge.max(1)[0]\n",
    "\n",
    "        #Image Dumps\n",
    "        if vi < 10:\n",
    "            dump_images.append([mask, seg_predictions, img_names])\n",
    "            heatmap_images.append([_edge, edge_predictions, img_names])\n",
    "\n",
    "        IOU_acc += fast_hist(seg_predictions.numpy().flatten(), mask.numpy().flatten(),\n",
    "                                   args.dataset_cls.num_classes)\n",
    "\n",
    "        del seg_out, edge_out, vi, data\n",
    "\n",
    "    if args.local_rank == 0:\n",
    "        evaluate_eval(args, net, optimizer, val_loss, mf_score, IOU_acc, dump_images, heatmap_images,\n",
    "                writer, curr_epoch, args.dataset_cls)\n",
    "\n",
    "    return val_loss.avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8903404",
   "metadata": {},
   "source": [
    "#### Part 2.3 - Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98939660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, net):\n",
    "    '''\n",
    "    Runs the evaluation loop and prints F score\n",
    "    val_loader: Data loader for validation\n",
    "    net: thet network\n",
    "    return: \n",
    "    '''\n",
    "    net.eval()\n",
    "    for thresh in args.eval_thresholds.split(','):\n",
    "        mf_score1 = AverageMeter()\n",
    "        mf_pc_score1 = AverageMeter()\n",
    "        ap_score1 = AverageMeter()\n",
    "        ap_pc_score1 = AverageMeter()\n",
    "        Fpc = np.zeros((args.dataset_cls.num_classes))\n",
    "        Fc = np.zeros((args.dataset_cls.num_classes))\n",
    "        for vi, data in enumerate(val_loader):\n",
    "            input, mask, edge, img_names = data\n",
    "            assert len(input.size()) == 4 and len(mask.size()) == 3\n",
    "            assert input.size()[2:] == mask.size()[1:]\n",
    "            h, w = mask.size()[1:]\n",
    "\n",
    "            batch_pixel_size = input.size(0) * input.size(2) * input.size(3)\n",
    "            input, mask_cuda, edge_cuda = input.cuda(), mask.cuda(), edge.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                seg_out, edge_out = net(input)\n",
    "\n",
    "            seg_predictions = seg_out.data.max(1)[1].cpu()\n",
    "            edge_predictions = edge_out.max(1)[0].cpu()\n",
    "\n",
    "            logging.info('evaluating: %d / %d' % (vi + 1, len(val_loader)))\n",
    "            _Fpc, _Fc = eval_mask_boundary(seg_predictions.numpy(), mask.numpy(), args.dataset_cls.num_classes, bound_th=float(thresh))\n",
    "            Fc += _Fc\n",
    "            Fpc += _Fpc\n",
    "\n",
    "            del seg_out, edge_out, vi, data\n",
    "\n",
    "        logging.info('Threshold: ' + thresh)\n",
    "        logging.info('F_Score: ' + str(np.sum(Fpc/Fc)/args.dataset_cls.num_classes))\n",
    "        logging.info('F_Score (Classwise): ' + str(Fpc/Fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4d92b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-10 01:28:09.672 train fine cities: ['train/aachen', 'train/bochum', 'train/bremen', 'train/cologne', 'train/darmstadt', 'train/dusseldorf', 'train/erfurt', 'train/hamburg', 'train/hanover', 'train/jena', 'train/krefeld', 'train/monchengladbach', 'train/strasbourg', 'train/stuttgart', 'train/tubingen', 'train/ulm', 'train/weimar', 'train/zurich']\n",
      "01-10 01:28:09.707 Cityscapes-train: 2975 images\n",
      "01-10 01:28:09.708 val fine cities: ['val/frankfurt', 'val/lindau', 'val/munster']\n",
      "01-10 01:28:09.714 Cityscapes-val: 500 images\n",
      "01-10 01:28:09.716 Using Per Image based weighted loss\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:222: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "01-10 01:28:09.718 Using Cross Entropy Loss\n",
      "C:\\Users\\Luca Petrescu\\Desktop\\GSCNN_Implementation\\network\\mynn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight)\n",
      "01-10 01:28:10.514 Model params = 137.3M\n",
      "01-10 01:28:10.547 Loaded weights from IMGNET classifier\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running....\n",
      "forward done\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 634.00 MiB. GPU 0 has a total capacty of 12.00 GiB of which 0 bytes is free. Of the allocated memory 25.66 GiB is allocated by PyTorch, and 843.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m start()\n",
      "Cell \u001b[1;32mIn[9], line 138\u001b[0m, in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m    134\u001b[0m cfg\u001b[38;5;241m.\u001b[39mimmutable(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    136\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m--> 138\u001b[0m train(train_loader, net, criterion, optim, epoch, writer)\n\u001b[0;32m    139\u001b[0m validate(val_loader, net, criterion_val,\n\u001b[0;32m    140\u001b[0m         optim, epoch, writer)\n",
      "Cell \u001b[1;32mIn[10], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, net, criterion, optimizer, curr_epoch, writer)\u001b[0m\n\u001b[0;32m     42\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mjoint_edgeseg_loss:\n\u001b[1;32m---> 45\u001b[0m     loss_dict \u001b[38;5;241m=\u001b[39m net(inputs, gts\u001b[38;5;241m=\u001b[39m(mask, edge))\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mseg_weight \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     48\u001b[0m         log_seg_loss \u001b[38;5;241m=\u001b[39m loss_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseg_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach_()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\parallel\\data_parallel.py:183\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m    185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, module_kwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\GSCNN_Implementation\\network\\gscnn.py:272\u001b[0m, in \u001b[0;36mGSCNN.forward\u001b[1;34m(self, inp, gts)\u001b[0m\n\u001b[0;32m    270\u001b[0m m5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmod5(m4)\n\u001b[0;32m    271\u001b[0m m6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmod6(m5)\n\u001b[1;32m--> 272\u001b[0m m7 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmod7(m6) \n\u001b[0;32m    274\u001b[0m s3 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdsn3(m3), x_size[\u001b[38;5;241m2\u001b[39m:],\n\u001b[0;32m    275\u001b[0m                     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    276\u001b[0m s4 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdsn4(m4), x_size[\u001b[38;5;241m2\u001b[39m:],\n\u001b[0;32m    277\u001b[0m                     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m'\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\GSCNN_Implementation\\network\\wider_resnet.py:175\u001b[0m, in \u001b[0;36mIdentityResidualBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    172\u001b[0m     shortcut \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m    173\u001b[0m     bn1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m--> 175\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs(bn1)\n\u001b[0;32m    176\u001b[0m out\u001b[38;5;241m.\u001b[39madd_(shortcut)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrack_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    180\u001b[0m     bn_training,\n\u001b[0;32m    181\u001b[0m     exponential_average_factor,\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps,\n\u001b[0;32m    183\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:2478\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2476\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbatch_norm(\n\u001b[0;32m   2479\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, training, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[0;32m   2480\u001b[0m )\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 634.00 MiB. GPU 0 has a total capacty of 12.00 GiB of which 0 bytes is free. Of the allocated memory 25.66 GiB is allocated by PyTorch, and 843.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb2009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09476d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
