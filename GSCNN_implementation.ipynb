{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecec23b0",
   "metadata": {},
   "source": [
    "## Implementation of GSCNN in a Jupyter Notebook\n",
    "\n",
    "In this Jupyter Notebook, we will implement GSCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5caf7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from network import Resnet\n",
    "from network.mynn import initialize_weights, Norm2d\n",
    "from network.wider_resnet import WiderResNetA2\n",
    "\n",
    "from my_functionals import GatedSpatialConv as gsc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0121768",
   "metadata": {},
   "source": [
    "The device we would like to train our network on would ideally to be out graphics card. However, in case we do not \n",
    "have a graphics card, then the device will be the CPU by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f08a6caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36d245",
   "metadata": {},
   "source": [
    "#### Part 1 - Implementing the Network Architecture\n",
    "\n",
    "Here we define the basic architecture of the network. In includes several classes, but we will explain each one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48d4296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crop(nn.Module):\n",
    "    def __init__(self, axis, offset):\n",
    "        super(Crop, self).__init__()\n",
    "        self.axis = axis\n",
    "        self.offset = offset\n",
    "\n",
    "    def forward(self, x, ref):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: input layer\n",
    "        :param ref: reference usually data in\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        for axis in range(self.axis, x.dim()):\n",
    "            ref_size = ref.size(axis)\n",
    "            indices = torch.arange(self.offset, self.offset + ref_size).long()\n",
    "            indices = x.data.new().resize_(indices.size()).copy_(indices).long()\n",
    "            x = x.index_select(axis, Variable(indices))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe72a79e",
   "metadata": {},
   "source": [
    "The **Crop** class is used to extract a subregion from an input tensor based on a reference tensor. \n",
    "It is a useful tool for data augmentation and other tasks that require extracting specific elements from a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b670cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyIdentity(nn.Module):\n",
    "    def __init__(self, axis, offset):\n",
    "        super(MyIdentity, self).__init__()\n",
    "        self.axis = axis\n",
    "        self.offset = offset\n",
    "\n",
    "    def forward(self, x, ref):\n",
    "        \"\"\"\n",
    "\n",
    "        :param x: input layer\n",
    "        :param ref: reference usually data in\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1256e6c4",
   "metadata": {},
   "source": [
    "The **MyIdentity** class in the provided code snippet is a custom neural network layer that simply returns the input tensor x without any modification. It takes two arguments in its constructor: **axis** and **offset**. These arguments are not used in the forward method and are likely just there to maintain consistency with the **Crop** class.\n",
    "\n",
    "The **forward** method of the **MyIdentity** class simply returns the input tensor **x** without any further processing. This indicates that the layer does not perform any transformation on the input data. It is essentially a pass-through layer that allows data to flow through the network without any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9f94888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SideOutputCrop(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the original implementation ConvTranspose2d (fixed) and crops\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_output, kernel_sz=None, stride=None, upconv_pad=0, do_crops=True):\n",
    "        super(SideOutputCrop, self).__init__()\n",
    "        self._do_crops = do_crops\n",
    "        self.conv = nn.Conv2d(num_output, out_channels=1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "\n",
    "        if kernel_sz is not None:\n",
    "            self.upsample = True\n",
    "            self.upsampled = nn.ConvTranspose2d(1, out_channels=1, kernel_size=kernel_sz, stride=stride,\n",
    "                                                padding=upconv_pad,\n",
    "                                                bias=False)\n",
    "            ##doing crops\n",
    "            if self._do_crops:\n",
    "                self.crops = Crop(2, offset=kernel_sz // 4)\n",
    "            else:\n",
    "                self.crops = MyIdentity(None, None)\n",
    "        else:\n",
    "            self.upsample = False\n",
    "\n",
    "    def forward(self, res, reference=None):\n",
    "        side_output = self.conv(res)\n",
    "        if self.upsample:\n",
    "            side_output = self.upsampled(side_output)\n",
    "            side_output = self.crops(side_output, reference)\n",
    "\n",
    "        return side_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b123072",
   "metadata": {},
   "source": [
    "The **SideOutputCrop** class is used to generate side output for a CNN. It can optionally apply upsampling and cropping to the side output. Upsampling is useful for increasing the spatial resolution of the side output, while cropping can be used to remove irrelevant or redundant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b4e61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AtrousSpatialPyramidPoolingModule(nn.Module):\n",
    "    '''\n",
    "    operations performed:\n",
    "      1x1 x depth\n",
    "      3x3 x depth dilation 6\n",
    "      3x3 x depth dilation 12\n",
    "      3x3 x depth dilation 18\n",
    "      image pooling\n",
    "      concatenate all together\n",
    "      Final 1x1 conv\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_dim, reduction_dim=256, output_stride=16, rates=[6, 12, 18]):\n",
    "        super(_AtrousSpatialPyramidPoolingModule, self).__init__()\n",
    "\n",
    "        # Check if we are using distributed BN and use the nn from encoding.nn\n",
    "        # library rather than using standard pytorch.nn\n",
    "\n",
    "        if output_stride == 8:\n",
    "            rates = [2 * r for r in rates]\n",
    "        elif output_stride == 16:\n",
    "            pass\n",
    "        else:\n",
    "            raise 'output stride of {} not supported'.format(output_stride)\n",
    "\n",
    "        self.features = []\n",
    "        # 1x1\n",
    "        self.features.append(\n",
    "            nn.Sequential(nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "                          Norm2d(reduction_dim), nn.ReLU(inplace=True)))\n",
    "        # other rates\n",
    "        for r in rates:\n",
    "            self.features.append(nn.Sequential(\n",
    "                nn.Conv2d(in_dim, reduction_dim, kernel_size=3,\n",
    "                          dilation=r, padding=r, bias=False),\n",
    "                Norm2d(reduction_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ))\n",
    "        self.features = torch.nn.ModuleList(self.features)\n",
    "\n",
    "        # img level features\n",
    "        self.img_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.img_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
    "            Norm2d(reduction_dim), nn.ReLU(inplace=True))\n",
    "        self.edge_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, reduction_dim, kernel_size=1, bias=False),\n",
    "            Norm2d(reduction_dim), nn.ReLU(inplace=True))\n",
    "         \n",
    "\n",
    "    def forward(self, x, edge):\n",
    "        x_size = x.size()\n",
    "\n",
    "        img_features = self.img_pooling(x)\n",
    "        img_features = self.img_conv(img_features)\n",
    "        img_features = F.interpolate(img_features, x_size[2:],\n",
    "                                     mode='bilinear',align_corners=True)\n",
    "        out = img_features\n",
    "\n",
    "        edge_features = F.interpolate(edge, x_size[2:],\n",
    "                                      mode='bilinear',align_corners=True)\n",
    "        edge_features = self.edge_conv(edge_features)\n",
    "        out = torch.cat((out, edge_features), 1)\n",
    "\n",
    "        for f in self.features:\n",
    "            y = f(x)\n",
    "            out = torch.cat((out, y), 1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935eb20d",
   "metadata": {},
   "source": [
    "The **_AtrousSpatialPyramidPoolingModule** class in the provided code snippet is a neural network module that performs atrous spatial pyramid pooling (ASPP) on the input feature map. ASPP is a technique for aggregating information from multiple feature scales in a single module. This can be useful for improving the performance of semantic segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e050349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSCNN(nn.Module):\n",
    "    '''\n",
    "    Wide_resnet version of DeepLabV3\n",
    "    mod1\n",
    "    pool2\n",
    "    mod2 str2\n",
    "    pool3\n",
    "    mod3-7\n",
    "\n",
    "      structure: [3, 3, 6, 3, 1, 1]\n",
    "      channels = [(128, 128), (256, 256), (512, 512), (512, 1024), (512, 1024, 2048),\n",
    "                  (1024, 2048, 4096)]\n",
    "    '''\n",
    "\n",
    "    def __init__(self, num_classes, trunk=None, criterion=None):\n",
    "        \n",
    "        super(GSCNN, self).__init__()\n",
    "        self.criterion = criterion\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        structure = [3, 3, 6, 3, 1, 1]\n",
    "        \n",
    "        wide_resnet = WiderResNetA2(structure, classes=1000, dilation=True)\n",
    "        wide_resnet = torch.nn.DataParallel(wide_resnet)\n",
    "        \n",
    "        wide_resnet = wide_resnet.module\n",
    "        self.mod1 = wide_resnet.mod1\n",
    "        self.mod2 = wide_resnet.mod2\n",
    "        self.mod3 = wide_resnet.mod3\n",
    "        self.mod4 = wide_resnet.mod4\n",
    "        self.mod5 = wide_resnet.mod5\n",
    "        self.mod6 = wide_resnet.mod6\n",
    "        self.mod7 = wide_resnet.mod7\n",
    "        self.pool2 = wide_resnet.pool2\n",
    "        self.pool3 = wide_resnet.pool3\n",
    "        self.interpolate = F.interpolate\n",
    "        del wide_resnet\n",
    "        \n",
    "        self.dsn1 = nn.Conv2d(64, 1, 1)\n",
    "        self.dsn3 = nn.Conv2d(256, 1, 1)\n",
    "        self.dsn4 = nn.Conv2d(512, 1, 1)\n",
    "        self.dsn7 = nn.Conv2d(4096, 1, 1)\n",
    "\n",
    "        self.res1 = Resnet.BasicBlock(64, 64, stride=1, downsample=None)\n",
    "        self.d1 = nn.Conv2d(64, 32, 1)\n",
    "        self.res2 = Resnet.BasicBlock(32, 32, stride=1, downsample=None)\n",
    "        self.d2 = nn.Conv2d(32, 16, 1)\n",
    "        self.res3 = Resnet.BasicBlock(16, 16, stride=1, downsample=None)\n",
    "        self.d3 = nn.Conv2d(16, 8, 1)\n",
    "        self.fuse = nn.Conv2d(8, 1, kernel_size=1, padding=0, bias=False)\n",
    "        \n",
    "        self.cw = nn.Conv2d(2, 1, kernel_size=1, padding=0, bias=False)\n",
    "\n",
    "        self.gate1 = gsc.GatedSpatialConv2d(32, 32)\n",
    "        self.gate2 = gsc.GatedSpatialConv2d(16, 16)\n",
    "        self.gate3 = gsc.GatedSpatialConv2d(8, 8)\n",
    "         \n",
    "        self.aspp = _AtrousSpatialPyramidPoolingModule(4096, 256,\n",
    "                                                       output_stride=8)\n",
    "\n",
    "        self.bot_fine = nn.Conv2d(128, 48, kernel_size=1, bias=False)\n",
    "        self.bot_aspp = nn.Conv2d(1280 + 256, 256, kernel_size=1, bias=False)\n",
    "        \n",
    "        self.final_seg = nn.Sequential(\n",
    "            nn.Conv2d(256 + 48, 256, kernel_size=3, padding=1, bias=False),\n",
    "            Norm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1, bias=False),\n",
    "            Norm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, num_classes, kernel_size=1, bias=False))\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        initialize_weights(self.final_seg)\n",
    "        \n",
    "    def forward(self, inp, gts=None):\n",
    "\n",
    "        x_size = inp.size() \n",
    "\n",
    "        # res 1\n",
    "        m1 = self.mod1(inp)\n",
    "\n",
    "        # res 2\n",
    "        m2 = self.mod2(self.pool2(m1))\n",
    "\n",
    "        # res 3\n",
    "        m3 = self.mod3(self.pool3(m2))\n",
    "\n",
    "        # res 4-7\n",
    "        m4 = self.mod4(m3)\n",
    "        m5 = self.mod5(m4)\n",
    "        m6 = self.mod6(m5)\n",
    "        m7 = self.mod7(m6) \n",
    "\n",
    "        s3 = F.interpolate(self.dsn3(m3), x_size[2:],\n",
    "                            mode='bilinear', align_corners=True)\n",
    "        s4 = F.interpolate(self.dsn4(m4), x_size[2:],\n",
    "                            mode='bilinear', align_corners=True)\n",
    "        s7 = F.interpolate(self.dsn7(m7), x_size[2:],\n",
    "                            mode='bilinear', align_corners=True)\n",
    "        \n",
    "        m1f = F.interpolate(m1, x_size[2:], mode='bilinear', align_corners=True)\n",
    "\n",
    "        im_arr = inp.cpu().numpy().transpose((0,2,3,1)).astype(np.uint8)\n",
    "        canny = np.zeros((x_size[0], 1, x_size[2], x_size[3]))\n",
    "        for i in range(x_size[0]):\n",
    "            canny[i] = cv2.Canny(im_arr[i],10,100)\n",
    "        canny = torch.from_numpy(canny).cuda().float()\n",
    "\n",
    "        cs = self.res1(m1f)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        cs = self.d1(cs)\n",
    "        cs = self.gate1(cs, s3)\n",
    "        cs = self.res2(cs)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        cs = self.d2(cs)\n",
    "        cs = self.gate2(cs, s4)\n",
    "        cs = self.res3(cs)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        cs = self.d3(cs)\n",
    "        cs = self.gate3(cs, s7)\n",
    "        cs = self.fuse(cs)\n",
    "        cs = F.interpolate(cs, x_size[2:],\n",
    "                           mode='bilinear', align_corners=True)\n",
    "        edge_out = self.sigmoid(cs)\n",
    "        cat = torch.cat((edge_out, canny), dim=1)\n",
    "        acts = self.cw(cat)\n",
    "        acts = self.sigmoid(acts)\n",
    "\n",
    "        # aspp\n",
    "        x = self.aspp(m7, acts)\n",
    "        dec0_up = self.bot_aspp(x)\n",
    "\n",
    "        dec0_fine = self.bot_fine(m2)\n",
    "        dec0_up = self.interpolate(dec0_up, m2.size()[2:], mode='bilinear',align_corners=True)\n",
    "        dec0 = [dec0_fine, dec0_up]\n",
    "        dec0 = torch.cat(dec0, 1)\n",
    "\n",
    "        dec1 = self.final_seg(dec0)  \n",
    "        seg_out = self.interpolate(dec1, x_size[2:], mode='bilinear')            \n",
    "       \n",
    "        if self.training:\n",
    "            return self.criterion((seg_out, edge_out), gts)              \n",
    "        else:\n",
    "            return seg_out, edge_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca76869",
   "metadata": {},
   "source": [
    "### Part 2 - Training and validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7d683ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import argparse\n",
    "from functools import partial\n",
    "from config import cfg, assert_and_infer_cfg\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils.misc import AverageMeter, prep_experiment, evaluate_eval, fast_hist\n",
    "from utils.f_boundary import eval_mask_boundary\n",
    "import datasets\n",
    "import loss\n",
    "import network\n",
    "import optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf1fd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6886026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument Parser\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "import argparse\n",
    "from functools import partial\n",
    "from config import cfg, assert_and_infer_cfg\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from utils.misc import AverageMeter, prep_experiment, evaluate_eval, fast_hist\n",
    "from utils.f_boundary import eval_mask_boundary\n",
    "import datasets\n",
    "import loss\n",
    "import network\n",
    "import optimizer\n",
    "\n",
    "# Argument Parser\n",
    "\n",
    "parser = argparse.ArgumentParser(description='GSCNN')\n",
    "\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.01)\n",
    "parser.add_argument('--arch', type=str, default='network.gscnn.GSCNN')\n",
    "parser.add_argument('--dataset', type=str, default='cityscapes')\n",
    "parser.add_argument('--cv', type=int, default=0,\n",
    "                    help='cross validation split')\n",
    "parser.add_argument('--joint_edgeseg_loss', action='store_true', default=True,\n",
    "                    help='joint loss')\n",
    "parser.add_argument('--img_wt_loss', action='store_true', default=False,\n",
    "                    help='per-image class-weighted loss')\n",
    "parser.add_argument('--batch_weighting', action='store_true', default=False,\n",
    "                    help='Batch weighting for class')\n",
    "parser.add_argument('--eval_thresholds', type=str, default='0.0005,0.001875,0.00375,0.005',\n",
    "                    help='Thresholds for boundary evaluation')\n",
    "parser.add_argument('--rescale', type=float, default=1.0,\n",
    "                    help='Rescaled LR Rate')\n",
    "parser.add_argument('--repoly', type=float, default=1.5,\n",
    "                    help='Rescaled Poly')\n",
    "\n",
    "parser.add_argument('--edge_weight', type=float, default=1.0,\n",
    "                    help='Edge loss weight for joint loss')\n",
    "parser.add_argument('--seg_weight', type=float, default=1.0,\n",
    "                    help='Segmentation loss weight for joint loss')\n",
    "parser.add_argument('--att_weight', type=float, default=1.0,\n",
    "                    help='Attention loss weight for joint loss')\n",
    "parser.add_argument('--dual_weight', type=float, default=1.0,\n",
    "                    help='Dual loss weight for joint loss')\n",
    "\n",
    "parser.add_argument('--evaluate', action='store_true', default=False)\n",
    "\n",
    "parser.add_argument(\"--local_rank\", default=0, type=int)\n",
    "\n",
    "parser.add_argument('--sgd', action='store_true', default=True)\n",
    "parser.add_argument('--sgd_finetuned',action='store_true',default=False)\n",
    "parser.add_argument('--adam', action='store_true', default=False)\n",
    "parser.add_argument('--amsgrad', action='store_true', default=False)\n",
    "\n",
    "parser.add_argument('--trunk', type=str, default='resnet101',\n",
    "                    help='trunk model, can be: resnet101 (default), resnet50')\n",
    "parser.add_argument('--max_epoch', type=int, default=175)\n",
    "parser.add_argument('--start_epoch', type=int, default=0)\n",
    "parser.add_argument('--color_aug', type=float,\n",
    "                    default=0.25, help='level of color augmentation')\n",
    "parser.add_argument('--rotate', type=float,\n",
    "                    default=0, help='rotation')\n",
    "parser.add_argument('--gblur', action='store_true', default=True)\n",
    "parser.add_argument('--bblur', action='store_true', default=False) \n",
    "parser.add_argument('--lr_schedule', type=str, default='poly',\n",
    "                    help='name of lr schedule: poly')\n",
    "parser.add_argument('--poly_exp', type=float, default=1.0,\n",
    "                    help='polynomial LR exponent')\n",
    "parser.add_argument('--bs_mult', type=int, default=2)\n",
    "parser.add_argument('--bs_mult_val', type=int, default=2)\n",
    "parser.add_argument('--crop_size', type=int, default=720,\n",
    "                    help='training crop size')\n",
    "parser.add_argument('--pre_size', type=int, default=None,\n",
    "                    help='resize image shorter edge to this before augmentation')\n",
    "parser.add_argument('--scale_min', type=float, default=0.5,\n",
    "                    help='dynamically scale training images down to this size')\n",
    "parser.add_argument('--scale_max', type=float, default=2.0,\n",
    "                    help='dynamically scale training images up to this size')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "parser.add_argument('--momentum', type=float, default=0.9)\n",
    "parser.add_argument('--snapshot', type=str, default=None)\n",
    "parser.add_argument('--restore_optimizer', action='store_true', default=False)\n",
    "parser.add_argument('--exp', type=str, default='default',\n",
    "                    help='experiment directory name')\n",
    "parser.add_argument('--tb_tag', type=str, default='',\n",
    "                    help='add tag to tb dir')\n",
    "parser.add_argument('--ckpt', type=str, default='logs/ckpt')\n",
    "parser.add_argument('--tb_path', type=str, default='logs/tb')\n",
    "parser.add_argument('--syncbn', action='store_true', default=True,\n",
    "                    help='Synchronized BN')\n",
    "parser.add_argument('--dump_augmentation_images', action='store_true', default=False,\n",
    "                    help='Synchronized BN')\n",
    "parser.add_argument('--test_mode', action='store_true', default=False,\n",
    "                    help='minimum testing (1 epoch run ) to verify nothing failed')\n",
    "parser.add_argument('-wb', '--wt_bound', type=float, default=1.0)\n",
    "parser.add_argument('--maxSkip', type=int, default=0)\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "def start():\n",
    "    assert_and_infer_cfg(args)\n",
    "    writer = prep_experiment(args,parser)\n",
    "    train_loader, val_loader, train_obj = datasets.setup_loaders(args)\n",
    "    criterion, criterion_val = loss.get_loss(args)\n",
    "    net = network.get_net(args, criterion)\n",
    "    optim, scheduler = optimizer.get_optimizer(args, net)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    if args.evaluate:\n",
    "        # Early evaluation for benchmarking\n",
    "        default_eval_epoch = 1\n",
    "        validate(val_loader, net, criterion_val,\n",
    "                    optim, default_eval_epoch, writer)\n",
    "        evaluate(val_loader, net)\n",
    "        return\n",
    "\n",
    "\n",
    "    #Main Loop\n",
    "    for epoch in range(args.start_epoch, args.max_epoch):\n",
    "    # Update EPOCH CTR\n",
    "        cfg.immutable(False)\n",
    "        cfg.EPOCH  = epoch\n",
    "        cfg.immutable(True)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        train(train_loader, net, criterion, optim, epoch, writer)\n",
    "        validate(val_loader, net, criterion_val,\n",
    "                optim, epoch, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0796b8c",
   "metadata": {},
   "source": [
    "#### Part 2.1 - Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70003415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train method\n",
    "\n",
    "def train(train_loader, net, criterion, optimizer, curr_epoch, writer):\n",
    "    '''\n",
    "    Runs the training loop per epoch\n",
    "    train_loader: Data loader for train\n",
    "    net: thet network\n",
    "    criterion: loss fn\n",
    "    optimizer: optimizer\n",
    "    curr_epoch: current epoch \n",
    "    writer: tensorboard writer\n",
    "    return: val_avg for step function if required\n",
    "    '''\n",
    "    net.train()\n",
    "\n",
    "    train_main_loss = AverageMeter()\n",
    "    train_edge_loss = AverageMeter()\n",
    "    train_seg_loss = AverageMeter()\n",
    "    train_att_loss = AverageMeter()\n",
    "    train_dual_loss = AverageMeter()\n",
    "    curr_iter = curr_epoch * len(train_loader)\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        if i==0:\n",
    "            print('running....')\n",
    "\n",
    "        inputs, mask, edge, _img_name = data\n",
    "\n",
    "        if torch.sum(torch.isnan(inputs)) > 0:\n",
    "            import pdb; pdb.set_trace()\n",
    "\n",
    "        batch_pixel_size = inputs.size(0) * inputs.size(2) * inputs.size(3)\n",
    "\n",
    "        inputs, mask, edge = inputs.cuda(), mask.cuda(), edge.cuda()\n",
    "\n",
    "        if i==0:\n",
    "            print('forward done')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        main_loss = None\n",
    "        loss_dict = None\n",
    "\n",
    "        if args.joint_edgeseg_loss:\n",
    "            loss_dict = net(inputs, gts=(mask, edge))\n",
    "            \n",
    "            if args.seg_weight > 0:\n",
    "                log_seg_loss = loss_dict['seg_loss'].mean().clone().detach_()\n",
    "                train_seg_loss.update(log_seg_loss.item(), batch_pixel_size)\n",
    "                main_loss = loss_dict['seg_loss']\n",
    "\n",
    "            if args.edge_weight > 0:\n",
    "                log_edge_loss = loss_dict['edge_loss'].mean().clone().detach_()\n",
    "                train_edge_loss.update(log_edge_loss.item(), batch_pixel_size)\n",
    "                if main_loss is not None:\n",
    "                    main_loss += loss_dict['edge_loss']\n",
    "                else:\n",
    "                    main_loss = loss_dict['edge_loss']\n",
    "            \n",
    "            if args.att_weight > 0:\n",
    "                log_att_loss = loss_dict['att_loss'].mean().clone().detach_()\n",
    "                train_att_loss.update(log_att_loss.item(), batch_pixel_size)\n",
    "                if main_loss is not None:\n",
    "                    main_loss += loss_dict['att_loss']\n",
    "                else:\n",
    "                    main_loss = loss_dict['att_loss']\n",
    "\n",
    "            if args.dual_weight > 0:\n",
    "                log_dual_loss = loss_dict['dual_loss'].mean().clone().detach_()\n",
    "                train_dual_loss.update(log_dual_loss.item(), batch_pixel_size)\n",
    "                if main_loss is not None:\n",
    "                    main_loss += loss_dict['dual_loss']\n",
    "                else:\n",
    "                    main_loss = loss_dict['dual_loss']\n",
    "\n",
    "        else:\n",
    "            main_loss = net(inputs, gts=mask)\n",
    "\n",
    "        main_loss = main_loss.mean()\n",
    "        log_main_loss = main_loss.clone().detach_()\n",
    "\n",
    "        train_main_loss.update(log_main_loss.item(), batch_pixel_size)\n",
    "\n",
    "        main_loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if i==0:\n",
    "            print('step 1 done')\n",
    "\n",
    "        curr_iter += 1\n",
    "\n",
    "        if args.local_rank == 0:\n",
    "            msg = '[epoch {}], [iter {} / {}], [train main loss {:0.6f}], [seg loss {:0.6f}], [edge loss {:0.6f}], [lr {:0.6f}]'.format(\n",
    "            curr_epoch, i + 1, len(train_loader), train_main_loss.avg, train_seg_loss.avg, train_edge_loss.avg, optimizer.param_groups[-1]['lr'] )\n",
    "\n",
    "            logging.info(msg)\n",
    "\n",
    "            # Log tensorboard metrics for each iteration of the training phase\n",
    "            writer.add_scalar('training/loss', (train_main_loss.val),\n",
    "                              curr_iter)\n",
    "            writer.add_scalar('training/lr', optimizer.param_groups[-1]['lr'],\n",
    "                              curr_iter)\n",
    "            if args.joint_edgeseg_loss:\n",
    "\n",
    "                writer.add_scalar('training/seg_loss', (train_seg_loss.val),\n",
    "                                  curr_iter)\n",
    "                writer.add_scalar('training/edge_loss', (train_edge_loss.val),\n",
    "                                  curr_iter)\n",
    "                writer.add_scalar('training/att_loss', (train_att_loss.val),\n",
    "                                  curr_iter)\n",
    "                writer.add_scalar('training/dual_loss', (train_dual_loss.val),\n",
    "                                  curr_iter)\n",
    "        if i > 5 and args.test_mode:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235f922",
   "metadata": {},
   "source": [
    "#### Part 2.2 - Validating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd75ee31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, net, criterion, optimizer, curr_epoch, writer):\n",
    "    '''\n",
    "    Runs the validation loop after each training epoch\n",
    "    val_loader: Data loader for validation\n",
    "    net: thet network\n",
    "    criterion: loss fn\n",
    "    optimizer: optimizer\n",
    "    curr_epoch: current epoch \n",
    "    writer: tensorboard writer\n",
    "    return: \n",
    "    '''\n",
    "    net.eval()\n",
    "    val_loss = AverageMeter()\n",
    "    mf_score = AverageMeter()\n",
    "    IOU_acc = 0\n",
    "    dump_images = []\n",
    "    heatmap_images = []\n",
    "    for vi, data in enumerate(val_loader):\n",
    "        input, mask, edge, img_names = data\n",
    "        assert len(input.size()) == 4 and len(mask.size()) == 3\n",
    "        assert input.size()[2:] == mask.size()[1:]\n",
    "        h, w = mask.size()[1:]\n",
    "\n",
    "        batch_pixel_size = input.size(0) * input.size(2) * input.size(3)\n",
    "        input, mask_cuda, edge_cuda = input.cuda(), mask.cuda(), edge.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            seg_out, edge_out = net(input)    # output = (1, 19, 713, 713)\n",
    "\n",
    "        if args.joint_edgeseg_loss:\n",
    "            loss_dict = criterion((seg_out, edge_out), (mask_cuda, edge_cuda))\n",
    "            val_loss.update(sum(loss_dict.values()).item(), batch_pixel_size)\n",
    "        else:\n",
    "            val_loss.update(criterion(seg_out, mask_cuda).item(), batch_pixel_size)\n",
    "\n",
    "        # Collect data from different GPU to a single GPU since\n",
    "        # encoding.parallel.criterionparallel function calculates distributed loss\n",
    "        # functions\n",
    "\n",
    "        seg_predictions = seg_out.data.max(1)[1].cpu()\n",
    "        edge_predictions = edge_out.max(1)[0].cpu()\n",
    "\n",
    "        #Logging\n",
    "        if vi % 20 == 0:\n",
    "            if args.local_rank == 0:\n",
    "                logging.info('validating: %d / %d' % (vi + 1, len(val_loader)))\n",
    "        if vi > 10 and args.test_mode:\n",
    "            break\n",
    "        _edge = edge.max(1)[0]\n",
    "\n",
    "        #Image Dumps\n",
    "        if vi < 10:\n",
    "            dump_images.append([mask, seg_predictions, img_names])\n",
    "            heatmap_images.append([_edge, edge_predictions, img_names])\n",
    "\n",
    "        IOU_acc += fast_hist(seg_predictions.numpy().flatten(), mask.numpy().flatten(),\n",
    "                                   args.dataset_cls.num_classes)\n",
    "\n",
    "        del seg_out, edge_out, vi, data\n",
    "\n",
    "    if args.local_rank == 0:\n",
    "        evaluate_eval(args, net, optimizer, val_loss, mf_score, IOU_acc, dump_images, heatmap_images,\n",
    "                writer, curr_epoch, args.dataset_cls)\n",
    "\n",
    "    return val_loss.avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8903404",
   "metadata": {},
   "source": [
    "#### Part 2.3 - Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98939660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_loader, net):\n",
    "    '''\n",
    "    Runs the evaluation loop and prints F score\n",
    "    val_loader: Data loader for validation\n",
    "    net: thet network\n",
    "    return: \n",
    "    '''\n",
    "    net.eval()\n",
    "    for thresh in args.eval_thresholds.split(','):\n",
    "        mf_score1 = AverageMeter()\n",
    "        mf_pc_score1 = AverageMeter()\n",
    "        ap_score1 = AverageMeter()\n",
    "        ap_pc_score1 = AverageMeter()\n",
    "        Fpc = np.zeros((args.dataset_cls.num_classes))\n",
    "        Fc = np.zeros((args.dataset_cls.num_classes))\n",
    "        for vi, data in enumerate(val_loader):\n",
    "            input, mask, edge, img_names = data\n",
    "            assert len(input.size()) == 4 and len(mask.size()) == 3\n",
    "            assert input.size()[2:] == mask.size()[1:]\n",
    "            h, w = mask.size()[1:]\n",
    "\n",
    "            batch_pixel_size = input.size(0) * input.size(2) * input.size(3)\n",
    "            input, mask_cuda, edge_cuda = input.cuda(), mask.cuda(), edge.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                seg_out, edge_out = net(input)\n",
    "\n",
    "            seg_predictions = seg_out.data.max(1)[1].cpu()\n",
    "            edge_predictions = edge_out.max(1)[0].cpu()\n",
    "\n",
    "            logging.info('evaluating: %d / %d' % (vi + 1, len(val_loader)))\n",
    "            _Fpc, _Fc = eval_mask_boundary(seg_predictions.numpy(), mask.numpy(), args.dataset_cls.num_classes, bound_th=float(thresh))\n",
    "            Fc += _Fc\n",
    "            Fpc += _Fpc\n",
    "\n",
    "            del seg_out, edge_out, vi, data\n",
    "\n",
    "        logging.info('Threshold: ' + thresh)\n",
    "        logging.info('F_Score: ' + str(np.sum(Fpc/Fc)/args.dataset_cls.num_classes))\n",
    "        logging.info('F_Score (Classwise): ' + str(Fpc/Fc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d92b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-10 01:40:17.712 train fine cities: ['train/aachen', 'train/bochum', 'train/bremen', 'train/cologne', 'train/darmstadt', 'train/dusseldorf', 'train/erfurt', 'train/hamburg', 'train/hanover', 'train/jena', 'train/krefeld', 'train/monchengladbach', 'train/strasbourg', 'train/stuttgart', 'train/tubingen', 'train/ulm', 'train/weimar', 'train/zurich']\n",
      "01-10 01:40:17.746 Cityscapes-train: 2975 images\n",
      "01-10 01:40:17.747 val fine cities: ['val/frankfurt', 'val/lindau', 'val/munster']\n",
      "01-10 01:40:17.753 Cityscapes-val: 500 images\n",
      "01-10 01:40:17.754 Using Per Image based weighted loss\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:222: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see https://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "01-10 01:40:17.818 Using Cross Entropy Loss\n",
      "C:\\Users\\Luca Petrescu\\Desktop\\GSCNN_Implementation\\network\\mynn.py:29: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(module.weight)\n",
      "01-10 01:40:18.565 Model params = 137.3M\n",
      "01-10 01:40:18.594 Loaded weights from IMGNET classifier\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running....\n",
      "forward done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca Petrescu\\Desktop\\GSCNN_Implementation\\loss.py:158: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  loss += self.nll_loss(F.log_softmax(inputs[i].unsqueeze(0)),\n",
      "C:\\Users\\Luca Petrescu\\anaconda3\\Lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "01-10 01:40:51.559 [epoch 0], [iter 1 / 1487], [train main loss 10.491802], [seg loss 4.786883], [edge loss 1.051445], [lr 0.009943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01-10 01:41:07.440 [epoch 0], [iter 2 / 1487], [train main loss nan], [seg loss nan], [edge loss 1.140847], [lr 0.009943]\n",
      "01-10 01:41:07.440 NaN or Inf found in input tensor.\n",
      "01-10 01:41:07.441 NaN or Inf found in input tensor.\n",
      "01-10 01:41:07.442 NaN or Inf found in input tensor.\n",
      "01-10 01:41:10.654 [epoch 0], [iter 3 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:41:10.655 NaN or Inf found in input tensor.\n",
      "01-10 01:41:10.655 NaN or Inf found in input tensor.\n",
      "01-10 01:41:10.656 NaN or Inf found in input tensor.\n",
      "01-10 01:41:10.658 NaN or Inf found in input tensor.\n",
      "01-10 01:41:10.659 NaN or Inf found in input tensor.\n",
      "01-10 01:41:26.491 [epoch 0], [iter 4 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:41:26.492 NaN or Inf found in input tensor.\n",
      "01-10 01:41:26.493 NaN or Inf found in input tensor.\n",
      "01-10 01:41:26.494 NaN or Inf found in input tensor.\n",
      "01-10 01:41:26.495 NaN or Inf found in input tensor.\n",
      "01-10 01:41:26.496 NaN or Inf found in input tensor.\n",
      "01-10 01:41:42.603 [epoch 0], [iter 5 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:41:42.604 NaN or Inf found in input tensor.\n",
      "01-10 01:41:42.605 NaN or Inf found in input tensor.\n",
      "01-10 01:41:42.606 NaN or Inf found in input tensor.\n",
      "01-10 01:41:42.606 NaN or Inf found in input tensor.\n",
      "01-10 01:41:42.607 NaN or Inf found in input tensor.\n",
      "01-10 01:41:58.703 [epoch 0], [iter 6 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:41:58.704 NaN or Inf found in input tensor.\n",
      "01-10 01:41:58.705 NaN or Inf found in input tensor.\n",
      "01-10 01:41:58.706 NaN or Inf found in input tensor.\n",
      "01-10 01:41:58.707 NaN or Inf found in input tensor.\n",
      "01-10 01:41:58.708 NaN or Inf found in input tensor.\n",
      "01-10 01:42:15.136 [epoch 0], [iter 7 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:42:15.137 NaN or Inf found in input tensor.\n",
      "01-10 01:42:15.139 NaN or Inf found in input tensor.\n",
      "01-10 01:42:15.140 NaN or Inf found in input tensor.\n",
      "01-10 01:42:15.141 NaN or Inf found in input tensor.\n",
      "01-10 01:42:15.142 NaN or Inf found in input tensor.\n",
      "01-10 01:42:31.426 [epoch 0], [iter 8 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:42:31.427 NaN or Inf found in input tensor.\n",
      "01-10 01:42:31.427 NaN or Inf found in input tensor.\n",
      "01-10 01:42:31.428 NaN or Inf found in input tensor.\n",
      "01-10 01:42:31.430 NaN or Inf found in input tensor.\n",
      "01-10 01:42:31.430 NaN or Inf found in input tensor.\n",
      "01-10 01:42:48.239 [epoch 0], [iter 9 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:42:48.240 NaN or Inf found in input tensor.\n",
      "01-10 01:42:48.240 NaN or Inf found in input tensor.\n",
      "01-10 01:42:48.242 NaN or Inf found in input tensor.\n",
      "01-10 01:42:48.243 NaN or Inf found in input tensor.\n",
      "01-10 01:42:48.244 NaN or Inf found in input tensor.\n",
      "01-10 01:43:05.258 [epoch 0], [iter 10 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:43:05.259 NaN or Inf found in input tensor.\n",
      "01-10 01:43:05.260 NaN or Inf found in input tensor.\n",
      "01-10 01:43:05.261 NaN or Inf found in input tensor.\n",
      "01-10 01:43:05.262 NaN or Inf found in input tensor.\n",
      "01-10 01:43:05.263 NaN or Inf found in input tensor.\n",
      "01-10 01:43:49.383 [epoch 0], [iter 11 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:43:49.383 NaN or Inf found in input tensor.\n",
      "01-10 01:43:49.384 NaN or Inf found in input tensor.\n",
      "01-10 01:43:49.385 NaN or Inf found in input tensor.\n",
      "01-10 01:43:49.386 NaN or Inf found in input tensor.\n",
      "01-10 01:43:49.388 NaN or Inf found in input tensor.\n",
      "01-10 01:44:06.196 [epoch 0], [iter 12 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:44:06.197 NaN or Inf found in input tensor.\n",
      "01-10 01:44:06.197 NaN or Inf found in input tensor.\n",
      "01-10 01:44:06.199 NaN or Inf found in input tensor.\n",
      "01-10 01:44:06.199 NaN or Inf found in input tensor.\n",
      "01-10 01:44:06.200 NaN or Inf found in input tensor.\n",
      "01-10 01:44:23.230 [epoch 0], [iter 13 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:44:23.231 NaN or Inf found in input tensor.\n",
      "01-10 01:44:23.232 NaN or Inf found in input tensor.\n",
      "01-10 01:44:23.234 NaN or Inf found in input tensor.\n",
      "01-10 01:44:23.235 NaN or Inf found in input tensor.\n",
      "01-10 01:44:23.237 NaN or Inf found in input tensor.\n",
      "01-10 01:44:39.876 [epoch 0], [iter 14 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:44:39.877 NaN or Inf found in input tensor.\n",
      "01-10 01:44:39.878 NaN or Inf found in input tensor.\n",
      "01-10 01:44:39.880 NaN or Inf found in input tensor.\n",
      "01-10 01:44:39.881 NaN or Inf found in input tensor.\n",
      "01-10 01:44:39.882 NaN or Inf found in input tensor.\n",
      "01-10 01:44:56.707 [epoch 0], [iter 15 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:44:56.708 NaN or Inf found in input tensor.\n",
      "01-10 01:44:56.709 NaN or Inf found in input tensor.\n",
      "01-10 01:44:56.710 NaN or Inf found in input tensor.\n",
      "01-10 01:44:56.711 NaN or Inf found in input tensor.\n",
      "01-10 01:44:56.712 NaN or Inf found in input tensor.\n",
      "01-10 01:45:13.307 [epoch 0], [iter 16 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:45:13.308 NaN or Inf found in input tensor.\n",
      "01-10 01:45:13.308 NaN or Inf found in input tensor.\n",
      "01-10 01:45:13.309 NaN or Inf found in input tensor.\n",
      "01-10 01:45:13.310 NaN or Inf found in input tensor.\n",
      "01-10 01:45:13.311 NaN or Inf found in input tensor.\n",
      "01-10 01:45:29.803 [epoch 0], [iter 17 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:45:29.804 NaN or Inf found in input tensor.\n",
      "01-10 01:45:29.804 NaN or Inf found in input tensor.\n",
      "01-10 01:45:29.806 NaN or Inf found in input tensor.\n",
      "01-10 01:45:29.806 NaN or Inf found in input tensor.\n",
      "01-10 01:45:29.807 NaN or Inf found in input tensor.\n",
      "01-10 01:45:46.119 [epoch 0], [iter 18 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:45:46.119 NaN or Inf found in input tensor.\n",
      "01-10 01:45:46.120 NaN or Inf found in input tensor.\n",
      "01-10 01:45:46.121 NaN or Inf found in input tensor.\n",
      "01-10 01:45:46.122 NaN or Inf found in input tensor.\n",
      "01-10 01:45:46.123 NaN or Inf found in input tensor.\n",
      "01-10 01:46:02.635 [epoch 0], [iter 19 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:46:02.637 NaN or Inf found in input tensor.\n",
      "01-10 01:46:02.638 NaN or Inf found in input tensor.\n",
      "01-10 01:46:02.639 NaN or Inf found in input tensor.\n",
      "01-10 01:46:02.640 NaN or Inf found in input tensor.\n",
      "01-10 01:46:02.641 NaN or Inf found in input tensor.\n",
      "01-10 01:46:19.433 [epoch 0], [iter 20 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:46:19.434 NaN or Inf found in input tensor.\n",
      "01-10 01:46:19.434 NaN or Inf found in input tensor.\n",
      "01-10 01:46:19.435 NaN or Inf found in input tensor.\n",
      "01-10 01:46:19.435 NaN or Inf found in input tensor.\n",
      "01-10 01:46:19.436 NaN or Inf found in input tensor.\n",
      "01-10 01:46:36.209 [epoch 0], [iter 21 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:46:36.210 NaN or Inf found in input tensor.\n",
      "01-10 01:46:36.211 NaN or Inf found in input tensor.\n",
      "01-10 01:46:36.212 NaN or Inf found in input tensor.\n",
      "01-10 01:46:36.213 NaN or Inf found in input tensor.\n",
      "01-10 01:46:36.214 NaN or Inf found in input tensor.\n",
      "01-10 01:46:53.792 [epoch 0], [iter 22 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:46:53.793 NaN or Inf found in input tensor.\n",
      "01-10 01:46:53.794 NaN or Inf found in input tensor.\n",
      "01-10 01:46:53.794 NaN or Inf found in input tensor.\n",
      "01-10 01:46:53.795 NaN or Inf found in input tensor.\n",
      "01-10 01:46:53.796 NaN or Inf found in input tensor.\n",
      "01-10 01:47:11.072 [epoch 0], [iter 23 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:47:11.073 NaN or Inf found in input tensor.\n",
      "01-10 01:47:11.073 NaN or Inf found in input tensor.\n",
      "01-10 01:47:11.075 NaN or Inf found in input tensor.\n",
      "01-10 01:47:11.076 NaN or Inf found in input tensor.\n",
      "01-10 01:47:11.077 NaN or Inf found in input tensor.\n",
      "01-10 01:47:28.624 [epoch 0], [iter 24 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:47:28.625 NaN or Inf found in input tensor.\n",
      "01-10 01:47:28.625 NaN or Inf found in input tensor.\n",
      "01-10 01:47:28.627 NaN or Inf found in input tensor.\n",
      "01-10 01:47:28.628 NaN or Inf found in input tensor.\n",
      "01-10 01:47:28.629 NaN or Inf found in input tensor.\n",
      "01-10 01:47:46.038 [epoch 0], [iter 25 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:47:46.039 NaN or Inf found in input tensor.\n",
      "01-10 01:47:46.040 NaN or Inf found in input tensor.\n",
      "01-10 01:47:46.041 NaN or Inf found in input tensor.\n",
      "01-10 01:47:46.042 NaN or Inf found in input tensor.\n",
      "01-10 01:47:46.043 NaN or Inf found in input tensor.\n",
      "01-10 01:48:04.091 [epoch 0], [iter 26 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:48:04.092 NaN or Inf found in input tensor.\n",
      "01-10 01:48:04.092 NaN or Inf found in input tensor.\n",
      "01-10 01:48:04.095 NaN or Inf found in input tensor.\n",
      "01-10 01:48:04.097 NaN or Inf found in input tensor.\n",
      "01-10 01:48:04.099 NaN or Inf found in input tensor.\n",
      "01-10 01:48:23.325 [epoch 0], [iter 27 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:48:23.326 NaN or Inf found in input tensor.\n",
      "01-10 01:48:23.327 NaN or Inf found in input tensor.\n",
      "01-10 01:48:23.328 NaN or Inf found in input tensor.\n",
      "01-10 01:48:23.329 NaN or Inf found in input tensor.\n",
      "01-10 01:48:23.329 NaN or Inf found in input tensor.\n",
      "01-10 01:48:41.588 [epoch 0], [iter 28 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:48:41.589 NaN or Inf found in input tensor.\n",
      "01-10 01:48:41.591 NaN or Inf found in input tensor.\n",
      "01-10 01:48:41.592 NaN or Inf found in input tensor.\n",
      "01-10 01:48:41.593 NaN or Inf found in input tensor.\n",
      "01-10 01:48:41.594 NaN or Inf found in input tensor.\n",
      "01-10 01:49:00.001 [epoch 0], [iter 29 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:49:00.001 NaN or Inf found in input tensor.\n",
      "01-10 01:49:00.002 NaN or Inf found in input tensor.\n",
      "01-10 01:49:00.004 NaN or Inf found in input tensor.\n",
      "01-10 01:49:00.005 NaN or Inf found in input tensor.\n",
      "01-10 01:49:00.006 NaN or Inf found in input tensor.\n",
      "01-10 01:49:18.341 [epoch 0], [iter 30 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:49:18.342 NaN or Inf found in input tensor.\n",
      "01-10 01:49:18.343 NaN or Inf found in input tensor.\n",
      "01-10 01:49:18.344 NaN or Inf found in input tensor.\n",
      "01-10 01:49:18.346 NaN or Inf found in input tensor.\n",
      "01-10 01:49:18.346 NaN or Inf found in input tensor.\n",
      "01-10 01:49:36.494 [epoch 0], [iter 31 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:49:36.494 NaN or Inf found in input tensor.\n",
      "01-10 01:49:36.495 NaN or Inf found in input tensor.\n",
      "01-10 01:49:36.496 NaN or Inf found in input tensor.\n",
      "01-10 01:49:36.496 NaN or Inf found in input tensor.\n",
      "01-10 01:49:36.498 NaN or Inf found in input tensor.\n",
      "01-10 01:49:54.455 [epoch 0], [iter 32 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:49:54.456 NaN or Inf found in input tensor.\n",
      "01-10 01:49:54.456 NaN or Inf found in input tensor.\n",
      "01-10 01:49:54.457 NaN or Inf found in input tensor.\n",
      "01-10 01:49:54.459 NaN or Inf found in input tensor.\n",
      "01-10 01:49:54.460 NaN or Inf found in input tensor.\n",
      "01-10 01:50:12.872 [epoch 0], [iter 33 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:50:12.873 NaN or Inf found in input tensor.\n",
      "01-10 01:50:12.873 NaN or Inf found in input tensor.\n",
      "01-10 01:50:12.874 NaN or Inf found in input tensor.\n",
      "01-10 01:50:12.875 NaN or Inf found in input tensor.\n",
      "01-10 01:50:12.876 NaN or Inf found in input tensor.\n",
      "01-10 01:50:31.454 [epoch 0], [iter 34 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:50:31.455 NaN or Inf found in input tensor.\n",
      "01-10 01:50:31.455 NaN or Inf found in input tensor.\n",
      "01-10 01:50:31.457 NaN or Inf found in input tensor.\n",
      "01-10 01:50:31.458 NaN or Inf found in input tensor.\n",
      "01-10 01:50:31.459 NaN or Inf found in input tensor.\n",
      "01-10 01:50:49.668 [epoch 0], [iter 35 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:50:49.668 NaN or Inf found in input tensor.\n",
      "01-10 01:50:49.669 NaN or Inf found in input tensor.\n",
      "01-10 01:50:49.670 NaN or Inf found in input tensor.\n",
      "01-10 01:50:49.671 NaN or Inf found in input tensor.\n",
      "01-10 01:50:49.672 NaN or Inf found in input tensor.\n",
      "01-10 01:51:07.194 [epoch 0], [iter 36 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:51:07.195 NaN or Inf found in input tensor.\n",
      "01-10 01:51:07.196 NaN or Inf found in input tensor.\n",
      "01-10 01:51:07.198 NaN or Inf found in input tensor.\n",
      "01-10 01:51:07.198 NaN or Inf found in input tensor.\n",
      "01-10 01:51:07.199 NaN or Inf found in input tensor.\n",
      "01-10 01:51:24.092 [epoch 0], [iter 37 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:51:24.093 NaN or Inf found in input tensor.\n",
      "01-10 01:51:24.094 NaN or Inf found in input tensor.\n",
      "01-10 01:51:24.095 NaN or Inf found in input tensor.\n",
      "01-10 01:51:24.096 NaN or Inf found in input tensor.\n",
      "01-10 01:51:24.096 NaN or Inf found in input tensor.\n",
      "01-10 01:51:40.833 [epoch 0], [iter 38 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:51:40.834 NaN or Inf found in input tensor.\n",
      "01-10 01:51:40.836 NaN or Inf found in input tensor.\n",
      "01-10 01:51:40.837 NaN or Inf found in input tensor.\n",
      "01-10 01:51:40.838 NaN or Inf found in input tensor.\n",
      "01-10 01:51:40.839 NaN or Inf found in input tensor.\n",
      "01-10 01:51:57.677 [epoch 0], [iter 39 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:51:57.678 NaN or Inf found in input tensor.\n",
      "01-10 01:51:57.679 NaN or Inf found in input tensor.\n",
      "01-10 01:51:57.680 NaN or Inf found in input tensor.\n",
      "01-10 01:51:57.681 NaN or Inf found in input tensor.\n",
      "01-10 01:51:57.681 NaN or Inf found in input tensor.\n",
      "01-10 01:52:16.381 [epoch 0], [iter 40 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:52:16.382 NaN or Inf found in input tensor.\n",
      "01-10 01:52:16.383 NaN or Inf found in input tensor.\n",
      "01-10 01:52:16.383 NaN or Inf found in input tensor.\n",
      "01-10 01:52:16.384 NaN or Inf found in input tensor.\n",
      "01-10 01:52:16.385 NaN or Inf found in input tensor.\n",
      "01-10 01:52:35.097 [epoch 0], [iter 41 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:52:35.098 NaN or Inf found in input tensor.\n",
      "01-10 01:52:35.099 NaN or Inf found in input tensor.\n",
      "01-10 01:52:35.100 NaN or Inf found in input tensor.\n",
      "01-10 01:52:35.100 NaN or Inf found in input tensor.\n",
      "01-10 01:52:35.102 NaN or Inf found in input tensor.\n",
      "01-10 01:52:53.851 [epoch 0], [iter 42 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:52:53.853 NaN or Inf found in input tensor.\n",
      "01-10 01:52:53.854 NaN or Inf found in input tensor.\n",
      "01-10 01:52:53.855 NaN or Inf found in input tensor.\n",
      "01-10 01:52:53.857 NaN or Inf found in input tensor.\n",
      "01-10 01:52:53.858 NaN or Inf found in input tensor.\n",
      "01-10 01:53:12.731 [epoch 0], [iter 43 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:53:12.731 NaN or Inf found in input tensor.\n",
      "01-10 01:53:12.732 NaN or Inf found in input tensor.\n",
      "01-10 01:53:12.733 NaN or Inf found in input tensor.\n",
      "01-10 01:53:12.734 NaN or Inf found in input tensor.\n",
      "01-10 01:53:12.734 NaN or Inf found in input tensor.\n",
      "01-10 01:53:31.791 [epoch 0], [iter 44 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:53:31.792 NaN or Inf found in input tensor.\n",
      "01-10 01:53:31.793 NaN or Inf found in input tensor.\n",
      "01-10 01:53:31.794 NaN or Inf found in input tensor.\n",
      "01-10 01:53:31.794 NaN or Inf found in input tensor.\n",
      "01-10 01:53:31.795 NaN or Inf found in input tensor.\n",
      "01-10 01:53:50.339 [epoch 0], [iter 45 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:53:50.339 NaN or Inf found in input tensor.\n",
      "01-10 01:53:50.341 NaN or Inf found in input tensor.\n",
      "01-10 01:53:50.342 NaN or Inf found in input tensor.\n",
      "01-10 01:53:50.343 NaN or Inf found in input tensor.\n",
      "01-10 01:53:50.344 NaN or Inf found in input tensor.\n",
      "01-10 01:54:08.886 [epoch 0], [iter 46 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:54:08.887 NaN or Inf found in input tensor.\n",
      "01-10 01:54:08.887 NaN or Inf found in input tensor.\n",
      "01-10 01:54:08.888 NaN or Inf found in input tensor.\n",
      "01-10 01:54:08.889 NaN or Inf found in input tensor.\n",
      "01-10 01:54:08.890 NaN or Inf found in input tensor.\n",
      "01-10 01:54:27.234 [epoch 0], [iter 47 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:54:27.235 NaN or Inf found in input tensor.\n",
      "01-10 01:54:27.235 NaN or Inf found in input tensor.\n",
      "01-10 01:54:27.236 NaN or Inf found in input tensor.\n",
      "01-10 01:54:27.237 NaN or Inf found in input tensor.\n",
      "01-10 01:54:27.238 NaN or Inf found in input tensor.\n",
      "01-10 01:54:45.816 [epoch 0], [iter 48 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:54:45.817 NaN or Inf found in input tensor.\n",
      "01-10 01:54:45.818 NaN or Inf found in input tensor.\n",
      "01-10 01:54:45.819 NaN or Inf found in input tensor.\n",
      "01-10 01:54:45.820 NaN or Inf found in input tensor.\n",
      "01-10 01:54:45.821 NaN or Inf found in input tensor.\n",
      "01-10 01:55:04.511 [epoch 0], [iter 49 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:55:04.512 NaN or Inf found in input tensor.\n",
      "01-10 01:55:04.513 NaN or Inf found in input tensor.\n",
      "01-10 01:55:04.514 NaN or Inf found in input tensor.\n",
      "01-10 01:55:04.515 NaN or Inf found in input tensor.\n",
      "01-10 01:55:04.516 NaN or Inf found in input tensor.\n",
      "01-10 01:55:22.165 [epoch 0], [iter 50 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:55:22.166 NaN or Inf found in input tensor.\n",
      "01-10 01:55:22.167 NaN or Inf found in input tensor.\n",
      "01-10 01:55:22.168 NaN or Inf found in input tensor.\n",
      "01-10 01:55:22.169 NaN or Inf found in input tensor.\n",
      "01-10 01:55:22.169 NaN or Inf found in input tensor.\n",
      "01-10 01:55:40.080 [epoch 0], [iter 51 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:55:40.081 NaN or Inf found in input tensor.\n",
      "01-10 01:55:40.081 NaN or Inf found in input tensor.\n",
      "01-10 01:55:40.083 NaN or Inf found in input tensor.\n",
      "01-10 01:55:40.084 NaN or Inf found in input tensor.\n",
      "01-10 01:55:40.085 NaN or Inf found in input tensor.\n",
      "01-10 01:55:57.114 [epoch 0], [iter 52 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:55:57.115 NaN or Inf found in input tensor.\n",
      "01-10 01:55:57.116 NaN or Inf found in input tensor.\n",
      "01-10 01:55:57.118 NaN or Inf found in input tensor.\n",
      "01-10 01:55:57.118 NaN or Inf found in input tensor.\n",
      "01-10 01:55:57.119 NaN or Inf found in input tensor.\n",
      "01-10 01:56:15.622 [epoch 0], [iter 53 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:56:15.623 NaN or Inf found in input tensor.\n",
      "01-10 01:56:15.624 NaN or Inf found in input tensor.\n",
      "01-10 01:56:15.625 NaN or Inf found in input tensor.\n",
      "01-10 01:56:15.626 NaN or Inf found in input tensor.\n",
      "01-10 01:56:15.626 NaN or Inf found in input tensor.\n",
      "01-10 01:56:33.877 [epoch 0], [iter 54 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:56:33.878 NaN or Inf found in input tensor.\n",
      "01-10 01:56:33.878 NaN or Inf found in input tensor.\n",
      "01-10 01:56:33.879 NaN or Inf found in input tensor.\n",
      "01-10 01:56:33.881 NaN or Inf found in input tensor.\n",
      "01-10 01:56:33.881 NaN or Inf found in input tensor.\n",
      "01-10 01:56:52.430 [epoch 0], [iter 55 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:56:52.431 NaN or Inf found in input tensor.\n",
      "01-10 01:56:52.433 NaN or Inf found in input tensor.\n",
      "01-10 01:56:52.434 NaN or Inf found in input tensor.\n",
      "01-10 01:56:52.435 NaN or Inf found in input tensor.\n",
      "01-10 01:56:52.436 NaN or Inf found in input tensor.\n",
      "01-10 01:57:10.932 [epoch 0], [iter 56 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:57:10.933 NaN or Inf found in input tensor.\n",
      "01-10 01:57:10.933 NaN or Inf found in input tensor.\n",
      "01-10 01:57:10.934 NaN or Inf found in input tensor.\n",
      "01-10 01:57:10.935 NaN or Inf found in input tensor.\n",
      "01-10 01:57:10.936 NaN or Inf found in input tensor.\n",
      "01-10 01:57:29.672 [epoch 0], [iter 57 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:57:29.672 NaN or Inf found in input tensor.\n",
      "01-10 01:57:29.674 NaN or Inf found in input tensor.\n",
      "01-10 01:57:29.674 NaN or Inf found in input tensor.\n",
      "01-10 01:57:29.675 NaN or Inf found in input tensor.\n",
      "01-10 01:57:29.676 NaN or Inf found in input tensor.\n",
      "01-10 01:57:47.977 [epoch 0], [iter 58 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:57:47.978 NaN or Inf found in input tensor.\n",
      "01-10 01:57:47.979 NaN or Inf found in input tensor.\n",
      "01-10 01:57:47.980 NaN or Inf found in input tensor.\n",
      "01-10 01:57:47.981 NaN or Inf found in input tensor.\n",
      "01-10 01:57:47.981 NaN or Inf found in input tensor.\n",
      "01-10 01:58:05.703 [epoch 0], [iter 59 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:58:05.704 NaN or Inf found in input tensor.\n",
      "01-10 01:58:05.704 NaN or Inf found in input tensor.\n",
      "01-10 01:58:05.705 NaN or Inf found in input tensor.\n",
      "01-10 01:58:05.706 NaN or Inf found in input tensor.\n",
      "01-10 01:58:05.707 NaN or Inf found in input tensor.\n",
      "01-10 01:58:23.973 [epoch 0], [iter 60 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:58:23.974 NaN or Inf found in input tensor.\n",
      "01-10 01:58:23.974 NaN or Inf found in input tensor.\n",
      "01-10 01:58:23.975 NaN or Inf found in input tensor.\n",
      "01-10 01:58:23.977 NaN or Inf found in input tensor.\n",
      "01-10 01:58:23.978 NaN or Inf found in input tensor.\n",
      "01-10 01:58:42.687 [epoch 0], [iter 61 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:58:42.688 NaN or Inf found in input tensor.\n",
      "01-10 01:58:42.689 NaN or Inf found in input tensor.\n",
      "01-10 01:58:42.689 NaN or Inf found in input tensor.\n",
      "01-10 01:58:42.691 NaN or Inf found in input tensor.\n",
      "01-10 01:58:42.692 NaN or Inf found in input tensor.\n",
      "01-10 01:59:01.519 [epoch 0], [iter 62 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:59:01.520 NaN or Inf found in input tensor.\n",
      "01-10 01:59:01.521 NaN or Inf found in input tensor.\n",
      "01-10 01:59:01.522 NaN or Inf found in input tensor.\n",
      "01-10 01:59:01.523 NaN or Inf found in input tensor.\n",
      "01-10 01:59:01.524 NaN or Inf found in input tensor.\n",
      "01-10 01:59:19.535 [epoch 0], [iter 63 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:59:19.536 NaN or Inf found in input tensor.\n",
      "01-10 01:59:19.537 NaN or Inf found in input tensor.\n",
      "01-10 01:59:19.537 NaN or Inf found in input tensor.\n",
      "01-10 01:59:19.538 NaN or Inf found in input tensor.\n",
      "01-10 01:59:19.539 NaN or Inf found in input tensor.\n",
      "01-10 01:59:37.006 [epoch 0], [iter 64 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:59:37.007 NaN or Inf found in input tensor.\n",
      "01-10 01:59:37.008 NaN or Inf found in input tensor.\n",
      "01-10 01:59:37.010 NaN or Inf found in input tensor.\n",
      "01-10 01:59:37.010 NaN or Inf found in input tensor.\n",
      "01-10 01:59:37.011 NaN or Inf found in input tensor.\n",
      "01-10 01:59:53.853 [epoch 0], [iter 65 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 01:59:53.854 NaN or Inf found in input tensor.\n",
      "01-10 01:59:53.854 NaN or Inf found in input tensor.\n",
      "01-10 01:59:53.856 NaN or Inf found in input tensor.\n",
      "01-10 01:59:53.857 NaN or Inf found in input tensor.\n",
      "01-10 01:59:53.858 NaN or Inf found in input tensor.\n",
      "01-10 02:00:12.240 [epoch 0], [iter 66 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:00:12.242 NaN or Inf found in input tensor.\n",
      "01-10 02:00:12.242 NaN or Inf found in input tensor.\n",
      "01-10 02:00:12.243 NaN or Inf found in input tensor.\n",
      "01-10 02:00:12.244 NaN or Inf found in input tensor.\n",
      "01-10 02:00:12.245 NaN or Inf found in input tensor.\n",
      "01-10 02:00:30.651 [epoch 0], [iter 67 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:00:30.651 NaN or Inf found in input tensor.\n",
      "01-10 02:00:30.652 NaN or Inf found in input tensor.\n",
      "01-10 02:00:30.653 NaN or Inf found in input tensor.\n",
      "01-10 02:00:30.653 NaN or Inf found in input tensor.\n",
      "01-10 02:00:30.655 NaN or Inf found in input tensor.\n",
      "01-10 02:00:48.997 [epoch 0], [iter 68 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:00:48.998 NaN or Inf found in input tensor.\n",
      "01-10 02:00:48.999 NaN or Inf found in input tensor.\n",
      "01-10 02:00:49.000 NaN or Inf found in input tensor.\n",
      "01-10 02:00:49.001 NaN or Inf found in input tensor.\n",
      "01-10 02:00:49.002 NaN or Inf found in input tensor.\n",
      "01-10 02:01:06.826 [epoch 0], [iter 69 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:01:06.827 NaN or Inf found in input tensor.\n",
      "01-10 02:01:06.827 NaN or Inf found in input tensor.\n",
      "01-10 02:01:06.828 NaN or Inf found in input tensor.\n",
      "01-10 02:01:06.829 NaN or Inf found in input tensor.\n",
      "01-10 02:01:06.830 NaN or Inf found in input tensor.\n",
      "01-10 02:01:23.908 [epoch 0], [iter 70 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:01:23.910 NaN or Inf found in input tensor.\n",
      "01-10 02:01:23.910 NaN or Inf found in input tensor.\n",
      "01-10 02:01:23.912 NaN or Inf found in input tensor.\n",
      "01-10 02:01:23.913 NaN or Inf found in input tensor.\n",
      "01-10 02:01:23.914 NaN or Inf found in input tensor.\n",
      "01-10 02:01:40.576 [epoch 0], [iter 71 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:01:40.577 NaN or Inf found in input tensor.\n",
      "01-10 02:01:40.577 NaN or Inf found in input tensor.\n",
      "01-10 02:01:40.580 NaN or Inf found in input tensor.\n",
      "01-10 02:01:40.581 NaN or Inf found in input tensor.\n",
      "01-10 02:01:40.582 NaN or Inf found in input tensor.\n",
      "01-10 02:01:57.235 [epoch 0], [iter 72 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:01:57.236 NaN or Inf found in input tensor.\n",
      "01-10 02:01:57.239 NaN or Inf found in input tensor.\n",
      "01-10 02:01:57.240 NaN or Inf found in input tensor.\n",
      "01-10 02:01:57.241 NaN or Inf found in input tensor.\n",
      "01-10 02:01:57.242 NaN or Inf found in input tensor.\n",
      "01-10 02:02:15.374 [epoch 0], [iter 73 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:02:15.376 NaN or Inf found in input tensor.\n",
      "01-10 02:02:15.376 NaN or Inf found in input tensor.\n",
      "01-10 02:02:15.377 NaN or Inf found in input tensor.\n",
      "01-10 02:02:15.378 NaN or Inf found in input tensor.\n",
      "01-10 02:02:15.379 NaN or Inf found in input tensor.\n",
      "01-10 02:02:34.081 [epoch 0], [iter 74 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:02:34.082 NaN or Inf found in input tensor.\n",
      "01-10 02:02:34.083 NaN or Inf found in input tensor.\n",
      "01-10 02:02:34.084 NaN or Inf found in input tensor.\n",
      "01-10 02:02:34.085 NaN or Inf found in input tensor.\n",
      "01-10 02:02:34.086 NaN or Inf found in input tensor.\n",
      "01-10 02:02:52.944 [epoch 0], [iter 75 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:02:52.945 NaN or Inf found in input tensor.\n",
      "01-10 02:02:52.946 NaN or Inf found in input tensor.\n",
      "01-10 02:02:52.946 NaN or Inf found in input tensor.\n",
      "01-10 02:02:52.947 NaN or Inf found in input tensor.\n",
      "01-10 02:02:52.948 NaN or Inf found in input tensor.\n",
      "01-10 02:03:10.799 [epoch 0], [iter 76 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:03:10.799 NaN or Inf found in input tensor.\n",
      "01-10 02:03:10.800 NaN or Inf found in input tensor.\n",
      "01-10 02:03:10.801 NaN or Inf found in input tensor.\n",
      "01-10 02:03:10.802 NaN or Inf found in input tensor.\n",
      "01-10 02:03:10.803 NaN or Inf found in input tensor.\n",
      "01-10 02:03:28.014 [epoch 0], [iter 77 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:03:28.015 NaN or Inf found in input tensor.\n",
      "01-10 02:03:28.016 NaN or Inf found in input tensor.\n",
      "01-10 02:03:28.017 NaN or Inf found in input tensor.\n",
      "01-10 02:03:28.018 NaN or Inf found in input tensor.\n",
      "01-10 02:03:28.019 NaN or Inf found in input tensor.\n",
      "01-10 02:03:45.037 [epoch 0], [iter 78 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:03:45.038 NaN or Inf found in input tensor.\n",
      "01-10 02:03:45.040 NaN or Inf found in input tensor.\n",
      "01-10 02:03:45.041 NaN or Inf found in input tensor.\n",
      "01-10 02:03:45.041 NaN or Inf found in input tensor.\n",
      "01-10 02:03:45.043 NaN or Inf found in input tensor.\n",
      "01-10 02:04:02.551 [epoch 0], [iter 79 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:04:02.552 NaN or Inf found in input tensor.\n",
      "01-10 02:04:02.552 NaN or Inf found in input tensor.\n",
      "01-10 02:04:02.554 NaN or Inf found in input tensor.\n",
      "01-10 02:04:02.555 NaN or Inf found in input tensor.\n",
      "01-10 02:04:02.556 NaN or Inf found in input tensor.\n",
      "01-10 02:04:19.785 [epoch 0], [iter 80 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:04:19.786 NaN or Inf found in input tensor.\n",
      "01-10 02:04:19.786 NaN or Inf found in input tensor.\n",
      "01-10 02:04:19.787 NaN or Inf found in input tensor.\n",
      "01-10 02:04:19.788 NaN or Inf found in input tensor.\n",
      "01-10 02:04:19.789 NaN or Inf found in input tensor.\n",
      "01-10 02:04:37.853 [epoch 0], [iter 81 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:04:37.854 NaN or Inf found in input tensor.\n",
      "01-10 02:04:37.855 NaN or Inf found in input tensor.\n",
      "01-10 02:04:37.856 NaN or Inf found in input tensor.\n",
      "01-10 02:04:37.858 NaN or Inf found in input tensor.\n",
      "01-10 02:04:37.859 NaN or Inf found in input tensor.\n",
      "01-10 02:04:55.092 [epoch 0], [iter 82 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:04:55.093 NaN or Inf found in input tensor.\n",
      "01-10 02:04:55.093 NaN or Inf found in input tensor.\n",
      "01-10 02:04:55.095 NaN or Inf found in input tensor.\n",
      "01-10 02:04:55.096 NaN or Inf found in input tensor.\n",
      "01-10 02:04:55.096 NaN or Inf found in input tensor.\n",
      "01-10 02:05:12.350 [epoch 0], [iter 83 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:05:12.352 NaN or Inf found in input tensor.\n",
      "01-10 02:05:12.352 NaN or Inf found in input tensor.\n",
      "01-10 02:05:12.354 NaN or Inf found in input tensor.\n",
      "01-10 02:05:12.355 NaN or Inf found in input tensor.\n",
      "01-10 02:05:12.355 NaN or Inf found in input tensor.\n",
      "01-10 02:05:29.567 [epoch 0], [iter 84 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:05:29.568 NaN or Inf found in input tensor.\n",
      "01-10 02:05:29.568 NaN or Inf found in input tensor.\n",
      "01-10 02:05:29.569 NaN or Inf found in input tensor.\n",
      "01-10 02:05:29.570 NaN or Inf found in input tensor.\n",
      "01-10 02:05:29.571 NaN or Inf found in input tensor.\n",
      "01-10 02:05:45.985 [epoch 0], [iter 85 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:05:45.986 NaN or Inf found in input tensor.\n",
      "01-10 02:05:45.987 NaN or Inf found in input tensor.\n",
      "01-10 02:05:45.988 NaN or Inf found in input tensor.\n",
      "01-10 02:05:45.989 NaN or Inf found in input tensor.\n",
      "01-10 02:05:45.990 NaN or Inf found in input tensor.\n",
      "01-10 02:06:03.539 [epoch 0], [iter 86 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:06:03.540 NaN or Inf found in input tensor.\n",
      "01-10 02:06:03.541 NaN or Inf found in input tensor.\n",
      "01-10 02:06:03.542 NaN or Inf found in input tensor.\n",
      "01-10 02:06:03.543 NaN or Inf found in input tensor.\n",
      "01-10 02:06:03.545 NaN or Inf found in input tensor.\n",
      "01-10 02:06:20.976 [epoch 0], [iter 87 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:06:20.977 NaN or Inf found in input tensor.\n",
      "01-10 02:06:20.978 NaN or Inf found in input tensor.\n",
      "01-10 02:06:20.978 NaN or Inf found in input tensor.\n",
      "01-10 02:06:20.980 NaN or Inf found in input tensor.\n",
      "01-10 02:06:20.981 NaN or Inf found in input tensor.\n",
      "01-10 02:06:37.630 [epoch 0], [iter 88 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:06:37.631 NaN or Inf found in input tensor.\n",
      "01-10 02:06:37.631 NaN or Inf found in input tensor.\n",
      "01-10 02:06:37.634 NaN or Inf found in input tensor.\n",
      "01-10 02:06:37.634 NaN or Inf found in input tensor.\n",
      "01-10 02:06:37.635 NaN or Inf found in input tensor.\n",
      "01-10 02:06:53.867 [epoch 0], [iter 89 / 1487], [train main loss nan], [seg loss nan], [edge loss nan], [lr 0.009943]\n",
      "01-10 02:06:53.868 NaN or Inf found in input tensor.\n",
      "01-10 02:06:53.869 NaN or Inf found in input tensor.\n",
      "01-10 02:06:53.870 NaN or Inf found in input tensor.\n",
      "01-10 02:06:53.871 NaN or Inf found in input tensor.\n",
      "01-10 02:06:53.872 NaN or Inf found in input tensor.\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb2009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09476d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
